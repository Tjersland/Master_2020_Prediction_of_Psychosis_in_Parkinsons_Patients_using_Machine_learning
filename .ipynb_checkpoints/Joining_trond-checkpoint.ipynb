{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Input the directory where your database is located \n",
    "os.chdir('C:/Users/Briggstone/Documents/Master 2020/Parkinson_PPMI')\n",
    "#os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Parkinson_PPMI')\n",
    "\n",
    "#Where you want the csv file of the merged data to be placed\n",
    "output_filepath = 'C:/Users/Briggstone/Documents/Master 2020')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we select the subset of patients with parkinson's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total subjects in original data table:  2200\n",
      "Number of subjects with parkinson's in data table: 489\n"
     ]
    }
   ],
   "source": [
    "#Reading the data table Screening demographics into a pandas dataframe\n",
    "data = pd.read_csv('_Subject_Characteristics/Screening___Demographics.csv') \n",
    "print(\"Number of total subjects in original data table: \", data.shape[0])\n",
    "\n",
    "#Discarding indviduals that do not have confirmed parkinson's, Everyone except APPRDX == 1.\n",
    "data = data.loc[data.APPRDX == 1]\n",
    "print(\"Number of subjects with parkinson's in data table:\", data.shape[0])\n",
    "\n",
    "#Selecting only PATNO column and reseting index (0-1-2 instead of 2-6-9). Index was weird due to dropping columns in the previous lines. \n",
    "pat_subset = pd.DataFrame(data.loc[:, \"PATNO\"].reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our data tables into pandas DataFrames and select the features we want from each data table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to 1 if using event_id for longitudinal joining or 0 if using infodt\n",
    "long_flag = 1\n",
    "LED = [\"INFODT\", \"EVENT_ID\"]\n",
    "\n",
    "\n",
    "#Importing data tables from non-motor and selecting relevant columns\n",
    "MOCA = pd.read_csv(\"Non-motor_Assessments/Montreal_Cognitive_Assessment__MoCA_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"MCATOT\"]]\n",
    "\n",
    "HPLT = pd.read_csv(\"Non-motor_Assessments/Hopkins_Verbal_Learning_Test.csv\").loc[:,[\"PATNO\", LED[long_flag], \"DVT_DELAYED_RECALL\"]]\n",
    "\n",
    "BJLO = pd.read_csv(\"Non-motor_Assessments/Benton_Judgment_of_Line_Orientation.csv\").loc[:,[\"PATNO\", LED[long_flag], \"JLO_TOTRAW\"]]\n",
    "\n",
    "LNSQ = pd.read_csv(\"Non-motor_Assessments/Letter_-_Number_Sequencing__PD_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"LNS_TOTRAW\"]]\n",
    "\n",
    "SEFL = pd.read_csv(\"Non-motor_Assessments/Semantic_Fluency.csv\").loc[:,[\"PATNO\", LED[long_flag], \"VLTANIM\", \"VLTVEG\", \"VLTFRUIT\"]]\n",
    "\n",
    "REMQ = pd.read_csv(\"Non-motor_Assessments/REM_Sleep_Disorder_Questionnaire.csv\").loc[:,[\"PATNO\", LED[long_flag], \"DRMVIVID\", \"DRMAGRAC\", \\\n",
    "    \"DRMNOCTB\", \"SLPLMBMV\", \"SLPINJUR\", \"DRMVERBL\", \"DRMFIGHT\", \"DRMUMV\", \"DRMOBJFL\", \"MVAWAKEN\", \"DRMREMEM\", \"SLPDSTRB\", \"STROKE\", \\\n",
    "    \"HETRA\", \"PARKISM\", \"RLS\", \"NARCLPSY\", \"DEPRS\", \"EPILEPSY\", \"BRNINFM\", \"CNSOTH\"]]\n",
    "\n",
    "GDSS = pd.read_csv(\"Non-motor_Assessments/Geriatric_Depression_Scale__Short_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"GDSSATIS\", \"GDSDROPD\", \\\n",
    "    \"GDSEMPTY\", \"GDSBORED\", \"GDSGSPIR\", \"GDSAFRAD\", \"GDSHAPPY\", \"GDSHLPLS\", \"GDSHOME\", \"GDSMEMRY\", \"GDSALIVE\", \"GDSWRTLS\", \"GDSENRGY\", \\\n",
    "    \"GDSHOPLS\", \"GDSBETER\"]]\n",
    "\n",
    "SIDT = pd.read_csv(\"Non-motor_Assessments/University_of_Pennsylvania_Smell_ID_Test.csv\").loc[:,[\"PATNO\", \"UPSITBK1\", \"UPSITBK2\", \\\n",
    "    \"UPSITBK3\", \"UPSITBK4\"]]\n",
    "\n",
    "EPSS = pd.read_csv(\"Non-motor_Assessments/Epworth_Sleepiness_Scale.csv\").loc[:,[\"PATNO\", LED[long_flag], \"ESS1\", \"ESS2\", \\\n",
    "    \"ESS3\", \"ESS4\", \"ESS5\", \"ESS6\", \"ESS7\", \"ESS8\"]]\n",
    "\n",
    "SCOP = pd.read_csv(\"Non-motor_Assessments/SCOPA-AUT.csv\").loc[:,[\"PATNO\", LED[long_flag], \"SCAU1\", \"SCAU2\", \\\n",
    "    \"SCAU3\", \"SCAU4\", \"SCAU5\", \"SCAU6\", \"SCAU7\", \"SCAU8\", \"SCAU9\", \"SCAU10\", \"SCAU11\", \"SCAU12\", \"SCAU13\", \\\n",
    "    \"SCAU14\", \"SCAU15\", \"SCAU16\", \"SCAU17\", \"SCAU18\", \"SCAU19\", \"SCAU20\", \"SCAU21\", \"SCAU22\", \"SCAU23\", \"SCAU24\", \"SCAU25\"]]\n",
    "\n",
    "\n",
    "\n",
    "#Importing data tables from motor\n",
    "MSU3 = pd.read_csv(\"Motor___MDS-UPDRS/MDS_UPDRS_Part_III.csv\").loc[:,[\"PATNO\", LED[long_flag], 'NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR', 'PAG_NAME', 'PD_MED_USE']]\n",
    "MSU1 = pd.read_csv(\"Motor___MDS-UPDRS/MDS_UPDRS_Part_I.csv\").loc[:,[\"PATNO\", LED[long_flag], \"NP1HALL\", \"NP1COG\"]]\n",
    "MSU2 = pd.read_csv (\"Motor___MDS-UPDRS/MDS_UPDRS_Part_II__Patient_Questionnaire.csv\").loc[:,[\"PATNO\", LED[long_flag], \"NP2TRMR\", \"NP2WALK\", \"NP2FREZ\"]]\n",
    "\n",
    "#Importing data tables from subject characteristics\n",
    "FMHS = pd.read_csv(\"_Subject_Characteristics/Family_History__PD_.csv\").loc[:,[\"PATNO\", \"BIOMOMPD\", \"BIODADPD\", \\\n",
    "    \"FULSIBPD\", \"HAFSIBPD\", \"MAGPARPD\", \"PAGPARPD\", \"MATAUPD\", \"PATAUPD\", \"KIDSPD\"]]\n",
    "SOEC = pd.read_csv(\"_Subject_Characteristics/Socio-Economics.csv\").loc[:,[\"PATNO\", \"EDUCYRS\"]]\n",
    "SCDE = pd.read_csv(\"_Subject_Characteristics/Screening___Demographics.csv\").loc[:,[\"PATNO\", \"PRJENRDT\", \"BIRTHDT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do any additional preprocessing on the data before we perform our data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC to BL for MOCA as it has no Baseline data\n",
    "MOCA.loc[MOCA[\"EVENT_ID\"] == \"SC\", \"EVENT_ID\"] = \"BL\"\n",
    "\n",
    "#Drop MSU3 data entries that are post drug-administering\n",
    "\n",
    "MSU3 = MSU3.drop(MSU3[ MSU3['PAG_NAME'] == \"NUPDRS3A\" ].index)\n",
    "MSU3 = MSU3.drop(\"PAG_NAME\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define the functions we need to calculate derived values from various variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for calculating derived values for various data tables\n",
    "\n",
    "def vlttot (df):\n",
    "    ''' Semantic Fluency\n",
    "    VLTANIM, VLTVEG,VLTFRUIT need to be summed in order to obtain a final score'''\n",
    "    \n",
    "    component_vars = [\"VLTANIM\", \"VLTVEG\", \"VLTFRUIT\"]\n",
    "    \n",
    "    df['VLTTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def remqtot(df):\n",
    "    '''REM sleep behavior disorder (RBD)'''\n",
    "    \n",
    "    component_vars = [\"STROKE\",\"HETRA\", \"PARKISM\", \"RLS\", \"NARCLPSY\", \"DEPRS\", \"EPILEPSY\", \"BRNINFM\", \"CNSOTH\"]\n",
    "        \n",
    "    score = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    \n",
    "    # 1 point if any of these component variables had a 1, else 0\n",
    "    score = pd.Series(np.where(score >= 1, 1, 0))\n",
    "    \n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    component_vars = [\"DRMVIVID\", \"DRMAGRAC\", \"DRMNOCTB\", \"SLPLMBMV\", \"SLPINJUR\", \\\n",
    "                      \"DRMVERBL\", \"DRMFIGHT\", \"DRMUMV\", \"DRMOBJFL\", \"MVAWAKEN\", \"DRMREMEM\", \"SLPDSTRB\"]\n",
    "    \n",
    "    score += df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "\n",
    "    df['REMTOT'] = score\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def gdsstot (df):\n",
    "    '''Geriatric Depression Scale'''\n",
    "    \n",
    "    component_vars = [\"GDSSATIS\", \"GDSDROPD\", \\\n",
    "    \"GDSEMPTY\", \"GDSBORED\", \"GDSGSPIR\", \"GDSAFRAD\", \"GDSHAPPY\", \"GDSHLPLS\", \"GDSHOME\", \"GDSMEMRY\", \"GDSALIVE\", \"GDSWRTLS\", \"GDSENRGY\", \\\n",
    "    \"GDSHOPLS\", \"GDSBETER\"]\n",
    "    \n",
    "    df['GDSSTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def sidttot (df):\n",
    "    '''Olfactory impairment: University of Pennsylvania Smell ID Test'''\n",
    "    component_vars = [\"UPSITBK1\", \"UPSITBK2\", \"UPSITBK3\", \"UPSITBK4\"]\n",
    "    \n",
    "    df['SIDTTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def epsstot (df):\n",
    "    '''Epworth Sleepiness Scale'''\n",
    "    \n",
    "    component_vars = [\"ESS1\", \"ESS2\", \\\n",
    "    \"ESS3\", \"ESS4\", \"ESS5\", \"ESS6\", \"ESS7\", \"ESS8\"]\n",
    "    \n",
    "    df['EPSSTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def scoptot(df):\n",
    "    '''Scales for Outcomes in Parkinson’s Disease–Autonomic'''\n",
    "    #SCOP is not a simple sum and needs additional preprocessing to get total score\n",
    "    # In SCAU1-21, 9 is converted to 3. In SCAU22-25, 9 is converted to 0\n",
    "    for i in range(1,26):\n",
    "        s = \"SCAU\" + str(i)\n",
    "        points = 0\n",
    "        if i < 22:\n",
    "            points = 3\n",
    "        df.loc[df[s] == 9, s] = points\n",
    "\n",
    "    component_vars = [\"SCAU1\", \"SCAU2\", \\\n",
    "    \"SCAU3\", \"SCAU4\", \"SCAU5\", \"SCAU6\", \"SCAU7\", \"SCAU8\", \"SCAU9\", \"SCAU10\", \"SCAU11\", \"SCAU12\", \"SCAU13\", \\\n",
    "    \"SCAU14\", \"SCAU15\", \"SCAU16\", \"SCAU17\", \"SCAU18\", \"SCAU19\", \"SCAU20\", \"SCAU21\", \"SCAU22\", \"SCAU23\", \"SCAU24\", \"SCAU25\"]\n",
    "    \n",
    "    df['SCOPTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "    \n",
    "\n",
    "def msu3tot(df):\n",
    "    '''Movement Disorders Society–Unified Parkinson Disease Rating Scale'''\n",
    "    \n",
    "    component_vars = ['NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR']\n",
    "       \n",
    "    df['MSU3TOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    #df.drop(component_vars, inplace = True, axis = 1) #cannot drop, variables needed in tremor and pigd\n",
    "\n",
    "    \n",
    "def tremor(df):\n",
    "    '''Tremor score'''\n",
    "    \n",
    "    component_vars = [\"NP2TRMR\", \"NP3PTRMR\", \"NP3PTRML\", \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \\\n",
    "    \"NP3RTALJ\", \"NP3RTCON\"]\n",
    "    \n",
    "    df['TREMOR'] = df.loc[:, component_vars].mean(axis = 1, skipna = False)\n",
    "    #df.drop(component_vars, inplace = True, axis = 1) #cannot drop, variables needed in tremor and pigd\n",
    "    \n",
    "    \n",
    "def pigd(df):\n",
    "    '''PIGD score'''\n",
    "    \n",
    "    component_vars = [\"NP2WALK\", \"NP2FREZ\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\"]\n",
    "    df['PIGD'] = df.loc[:, component_vars].mean(axis = 1, skipna = False)\n",
    "    \n",
    "    component_vars = ['NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR', \"NP2TRMR\", \"NP2WALK\", \"NP2FREZ\" ]\n",
    "    #cannot drop before we discuss missing values\n",
    "    #df.drop(component_vars, inplace = True, axis = 1) #drop everything from msu3tot, tremor and pig\n",
    "    \n",
    "\n",
    "def td_pigd_ratio(df):\n",
    "    '''Tremor/PIGD ratio'''\n",
    "    \n",
    "    component_vars = ['TREMOR', 'PIGD']\n",
    "    df['TD_PIGD_RATIO'] = df.apply(lambda x: ratio(x['TREMOR'], x['PIGD']), axis=1)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def ratio(x, y):\n",
    "    ''' Calculate TD/PGID ratio'''\n",
    "    \n",
    "    if y == 0:\n",
    "        if x == 0:\n",
    "            ratio = 0 #indeterminate\n",
    "        else: \n",
    "            ratio =1 #TD\n",
    "    elif x/y >= 1.15:\n",
    "        ratio = 1 #TD\n",
    "    elif x/y <= 0.9:\n",
    "        ratio = 2 #PIGD\n",
    "    else:\n",
    "        ratio = 0 #indeterminate \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we perform our data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of join: Merge non-longitudinal data\n",
    "pat_subset = pd.DataFrame(pat_subset)\n",
    "data = pat_subset.merge(FMHS, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SOEC, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SCDE, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SIDT, how = \"inner\", on = \"PATNO\")\n",
    "\n",
    "\n",
    "#Second step of join: Merge in longitudinal data\n",
    "\n",
    "#This data table has duplicate entries for the same data, test is done before drug is administered and after\n",
    "data = data.merge(MSU3, how = \"inner\", on =\"PATNO\")\n",
    "\n",
    "data = data.merge(MSU1, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(MOCA, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(HPLT, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(BJLO, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(LNSQ, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(SEFL, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(GDSS, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(EPSS, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(SCOP, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(REMQ, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(MSU2, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do some additional processing post merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing birthdate and project enrollment date and adding age as a function of these two columns\n",
    "\n",
    "tempdata = data.loc[:, [\"PRJENRDT\", \"BIRTHDT\"]]\n",
    "tempdata.PRJENRDT = tempdata.apply(lambda row_wise: int(row_wise[\"PRJENRDT\"][-4:]), axis = 1)\n",
    "tempdata.BIRTHDT = tempdata.apply(lambda row_wise: int(row_wise[\"BIRTHDT\"]), axis = 1)\n",
    "data [\"AGE_BL\"] = tempdata.PRJENRDT - tempdata.BIRTHDT\n",
    "data = data.drop([\"PRJENRDT\", \"BIRTHDT\"], axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we process missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We deal with missing demographic PD questions by filling the missing entries with no. \n",
    "# The rationale is that the proportion of subjects who answers 0 in the non-missing entries is much larger than the proportion of subjects who answers 1 in the non-missing entries\n",
    "vars = [\"BIOMOMPD\",\"BIODADPD\", \"FULSIBPD\", \"HAFSIBPD\", \"MAGPARPD\", \"PAGPARPD\", \"MATAUPD\", \"PATAUPD\", \"KIDSPD\" ]\n",
    "data [vars] = data[vars].fillna(0)\n",
    "\n",
    "# TEMPORARY FIX: We deal with missing UPSIT data by deleting subject with PATNO 3413\n",
    "#index = data[data.PATNO == 3413].index\n",
    "#data.drop(axis = 0, index = index, inplace = True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we explore our missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UPSITBK1                 1\n",
      "UPSITBK2                 1\n",
      "UPSITBK3                 1\n",
      "UPSITBK4                 1\n",
      "NP3FTAPL                 1\n",
      "NP3HMOVL                 1\n",
      "NP3PRSPL                 1\n",
      "NP3PSTBL                 8\n",
      "NP3PTRMR                 1\n",
      "NP3TTAPR                 1\n",
      "MCATOT                   2\n",
      "DVT_DELAYED_RECALL       3\n",
      "JLO_TOTRAW               3\n",
      "GDSSATIS                 1\n",
      "GDSHAPPY                 1\n",
      "GDSENRGY                 2\n",
      "ESS1                     1\n",
      "ESS2                     1\n",
      "ESS3                     1\n",
      "ESS4                     1\n",
      "ESS5                     1\n",
      "ESS6                     1\n",
      "ESS7                     1\n",
      "ESS8                     3\n",
      "SCAU1                    1\n",
      "SCAU2                    1\n",
      "SCAU3                    2\n",
      "SCAU4                    1\n",
      "SCAU5                    1\n",
      "SCAU6                    1\n",
      "SCAU7                    9\n",
      "SCAU8                    1\n",
      "SCAU9                    1\n",
      "SCAU10                   1\n",
      "SCAU11                   2\n",
      "SCAU12                   2\n",
      "SCAU13                   1\n",
      "SCAU14                   1\n",
      "SCAU15                   1\n",
      "SCAU16                   1\n",
      "SCAU17                   1\n",
      "SCAU18                   2\n",
      "SCAU19                   1\n",
      "SCAU20                   1\n",
      "SCAU21                   2\n",
      "SCAU22                 788\n",
      "SCAU23                 788\n",
      "SCAU24                1557\n",
      "SCAU25                1557\n",
      "DRMNOCTB                 6\n",
      "SLPLMBMV                 1\n",
      "SLPINJUR                 2\n",
      "DRMVERBL                 1\n",
      "DRMFIGHT                 2\n",
      "DRMUMV                   2\n",
      "DRMOBJFL                 1\n",
      "CNSOTH                  25\n",
      "dtype: int64\n",
      "\n",
      " PATNO with missing non-trivial entries\n",
      "425\n",
      "\n",
      "Entries with missing NP3PTRMR\n",
      "[3815]\n",
      "\n",
      "Entries with missing NP3PSTBL\n",
      "[3058 3059 3607 3168 3307 3080 3181]\n"
     ]
    }
   ],
   "source": [
    "null_columns=data.columns[data.isnull().any()]\n",
    "print(data[null_columns].isnull().sum())\n",
    "\n",
    "print(\"\\n PATNO with missing non-trivial entries\")\n",
    "null_data = data[data.isnull().any(axis=1)]\n",
    "print(null_data.PATNO.unique().size)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# TREMOR is a score depending on: \n",
    "# \"NP2TRMR\", \"NP3PTRMR\", \"NP3PTRML\", \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \"NP3RTALJ\", \"NP3RTCON\"\n",
    "print(\"\\nEntries with missing NP3PTRMR\")\n",
    "print(data[data['NP3PTRMR'].isnull()][[\"PATNO\", LED[long_flag], \"NP3PTRMR\"]].PATNO.unique())\n",
    "\n",
    "# PGID is a score depending on:\n",
    "# \"NP2WALK\", \"NP2FREZ\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\"\n",
    "print(\"\\nEntries with missing NP3PSTBL\")\n",
    "print(data[data['NP3PSTBL'].isnull()][[\"PATNO\", LED[long_flag], \"NP3PSTBL\"]].PATNO.unique())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (2341, 130)\n",
      "Number of unique PATNO: 425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Inspecting the merged data\n",
    "\n",
    "#np.sort(data.columns.values)\n",
    "print( \"Data shape\", data.shape)\n",
    "print( \"Number of unique PATNO:\", data.PATNO.unique().size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for encoding and dichotomizing variables\n",
    "\n",
    "def famhist(df):\n",
    "    '''Family history of Parkinson's Disease'''\n",
    "    \n",
    "    component_vars = [\"BIOMOMPD\", \"BIODADPD\", \"FULSIBPD\", \"HAFSIBPD\", \"MAGPARPD\", \"PAGPARPD\", \"MATAUPD\", \"PATAUPD\", \"KIDSPD\"]\n",
    "        \n",
    "    score = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    \n",
    "    # if score >= 1 then 1, else 0\n",
    "    # if score = NaN, then 0\n",
    "    score = pd.Series(np.where(score >= 1, 1, 0))\n",
    "    \n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "    df['FAMHIST'] = score\n",
    "    \n",
    "    \n",
    "def sleepy(df):\n",
    "    '''Dichotomize EPSSTOT, Epworth Sleepiness Scale'''\n",
    "    \n",
    "    # if score < 10 subjects will be classified as 0 (not sleepy)\n",
    "    # if score >= 10 subject will be classified as 1 (sleepy).\n",
    "    df['SLEEPY'] = df['EPSSTOT'].apply(lambda x: np.where(x >=10, 1, 0))\n",
    "\n",
    "    df.drop('EPSSTOT', inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "def depr(df):\n",
    "    '''Dichotomize GDSSTOT, Geriatric Depression Scale'''\n",
    "    \n",
    "    # if score <5 subjects will be classified as 0 (non-depressed).\n",
    "    # if score >= 5 subjects will be classified as 1 (depressed) \n",
    "    df['DEPR'] = df['GDSSTOT'].apply(lambda x: np.where(x >=5, 1, 0))\n",
    "\n",
    "    df.drop('GDSSTOT', inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "def rbd(df):\n",
    "    '''Dichotomize REMTOT, REM sleep behavior disorder (RBD)'''\n",
    "       \n",
    "    # if score <5 subjects will be classified as 0 (RBD negative).\n",
    "    # if score >= 5 subjects will be classified as 1 (RBD positive) \n",
    "    df['RBD'] = df['REMTOT'].apply(lambda x: np.where(x >=5, 1, 0))\n",
    "\n",
    "    df.drop('REMTOT', inplace = True, axis = 1)\n",
    "    \n",
    "\n",
    "def hall(df):\n",
    "    '''Dihotomize NP1HALL dependent variable'''\n",
    "    \n",
    "    # if the patient has not suffered hallucinations, we consider it 0\n",
    "    # if the patient has suffered >= 1 times hallucinations, we consider it 1   \n",
    "    df['HALL'] = df['NP1HALL'].apply(lambda x: np.where(x >=1, 1, 0))\n",
    "\n",
    "    df.drop('NP1HALL', inplace = True, axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
