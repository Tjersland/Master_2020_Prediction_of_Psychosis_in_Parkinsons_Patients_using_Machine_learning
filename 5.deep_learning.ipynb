{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "''' Input the directory where your folder created in main.processing.ipynb is located '''\n",
    "#os.chdir('C:/Users/Trond/Documents/Master 2020/Processed data')\n",
    "os.chdir('C:/Users/Briggstone/Documents/Master 2020/Processed data')\n",
    "#os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data')\n",
    "\n",
    "''' Where you want the output of this notebook to be placed '''\n",
    "output_filepath = 'C:/Users/Briggstone/Documents/Master 2020/Processed data'\n",
    "#output_filepath = 'C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# To get consistent results on functions which make us of np.random\n",
    "np.random.seed(31415)\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "# Which folder of preprocessed data we want to use\n",
    "FOLDER_NAME = \"Deep_Learning_Approach\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define additional preprocessing functions specific for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Generator used to deliver batches of size 1\n",
    "def create_generator_arrays(df):\n",
    "    \n",
    "    df_x = []\n",
    "    df_y = []\n",
    "    \n",
    "    unique_subjects = df.PATNO.unique()  \n",
    "    \n",
    "    for u in unique_subjects:\n",
    "        \n",
    "        subject_data = df.loc[df.PATNO == u, :]\n",
    "        \n",
    "        y = subject_data.tail(1).HALL.values[0]\n",
    "        y = np.expand_dims(y, axis = 0)\n",
    "        df_y.append(y)\n",
    "        \n",
    "        subject_data.drop([\"HALL\", \"PATNO\"], axis = 1, inplace = True)\n",
    "        \n",
    "        x = subject_data.to_numpy()\n",
    "        x = np.expand_dims(x, axis=0)\n",
    "        df_x.append(x)\n",
    "        \n",
    "    return df_x,df_y\n",
    "\n",
    "\n",
    "\n",
    "#Need to generate a validation set as we use this for early stopping and model validation for deep learning\n",
    "#Generates a validation set of equal size to test set\n",
    "def train_validation_test_split (train,test):\n",
    "    \n",
    "    num_of_unique_subjects_train = train.PATNO.unique().size  \n",
    "    num_of_unique_subjects_test = test.PATNO.unique().size  \n",
    "    total_unique_subjects = num_of_unique_subjects_train + num_of_unique_subjects_test\n",
    "    \n",
    "    train_ratio = num_of_unique_subjects_train / total_unique_subjects\n",
    "    test_ratio = num_of_unique_subjects_test / total_unique_subjects\n",
    "    \n",
    "    #ratio to take from training set to make validation as large as test set\n",
    "    \n",
    "    validation_ratio = test_ratio / train_ratio\n",
    "    \n",
    "    tempdata = pd.DataFrame(train.PATNO.unique(), columns = [\"PATNO\"])\n",
    "\n",
    "    HALL_EVER = []\n",
    "    for id in train.PATNO.unique():\n",
    "\n",
    "        if train.loc[(train.PATNO == id) & (train.HALL == 1), \"HALL\"].empty:\n",
    "            HALL_EVER.append(0)\n",
    "        else:\n",
    "            HALL_EVER.append(1)\n",
    "\n",
    "    Y = HALL_EVER\n",
    "    X = tempdata\n",
    "\n",
    "    temptrain, validation, _, _ = train_test_split( X, Y, test_size= validation_ratio, random_state= 1, stratify= Y, shuffle = True)\n",
    "\n",
    "    temptrain = train.merge(temptrain, how = \"inner\", on = \"PATNO\")\n",
    "    validation = train.merge(validation, how = \"inner\", on = \"PATNO\")\n",
    "    \n",
    "    train = temptrain\n",
    "    \n",
    "    return train,validation,test\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do additional preprocessing specific for LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Briggstone\\AppData\\Roaming\\Python\\Python37\\site-packages\\pandas\\core\\frame.py:3997: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects train:  239\n",
      "Number of subjects validation:  80\n",
      "Number of subjects test:  80\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(FOLDER_NAME + '/train.csv')\n",
    "test = pd.read_csv(FOLDER_NAME + '/test.csv')\n",
    "FP_DF = pd.read_csv(FOLDER_NAME + '/FP_DF.csv')\n",
    "\n",
    "#Used for sensitivty vs year plot\n",
    "test_PATNO = pd.DataFrame(test[\"PATNO\"].unique(), columns = [\"PATNO\"])\n",
    "test_FP = FP_DF.merge(test_PATNO, how = \"inner\", on = \"PATNO\")\n",
    "\n",
    "# We don't implement samling for deep learning due to poor results on other algorithms\n",
    "train.drop([\"SAMPLING\"], axis = 1, inplace  = True)\n",
    "\n",
    "# We split into train,validation and test\n",
    "train,validation,test = train_validation_test_split (train,test)\n",
    "\n",
    "#Creating generators arrays\n",
    "train_x, train_y = create_generator_arrays(train)\n",
    "validation_x, validation_y = create_generator_arrays(validation)\n",
    "test_x, test_y = create_generator_arrays(test)\n",
    "\n",
    "#Getting values necessary for generators and lstm to work\n",
    "num_of_dims = train.shape[1] - 2\n",
    "num_of_unique_subjects_train = train.PATNO.unique().size  \n",
    "num_of_unique_subjects_validation = validation.PATNO.unique().size\n",
    "num_of_unique_subjects_test = test.PATNO.unique().size  \n",
    "\n",
    "#Printing out data for number of subjects in each data set\n",
    "print(\"Number of subjects train: \", num_of_unique_subjects_train)\n",
    "print(\"Number of subjects validation: \", num_of_unique_subjects_validation)\n",
    "print(\"Number of subjects test: \", num_of_unique_subjects_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this section we define helper functions for the LSTM implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as met\n",
    "\n",
    "def data_generator (x,y, num_of_epochs):\n",
    "    for e in range(num_of_epochs):\n",
    "        for i in range (len(x)):\n",
    "            yield x[i], y[i]\n",
    "            \n",
    "def scorer_helper_function(y_true,y_pred,scorer_string):\n",
    "    \n",
    "    if scorer_string == \"accuracy\":\n",
    "        return met.accuracy_score(y_true, y_pred)\n",
    "    elif scorer_string == \"precision\":\n",
    "        return met.precision_score(y_true,y_pred)\n",
    "    elif scorer_string == \"sensitivity\":\n",
    "        return met.recall_score(y_true,y_pred)\n",
    "    elif scorer_string == \"specificity\":\n",
    "        return met.recall_score(y_true,y_pred, pos_label = 0)\n",
    "    elif scorer_string == \"f1\":\n",
    "        return met.f1_score(y_true,y_pred)\n",
    "    elif scorer_string == \"roc_auc\":\n",
    "        return met.roc_auc_score(y_true,y_pred)\n",
    "    elif scorer_string == \"MCC\":\n",
    "        return met.matthews_corrcoef(y_true,y_pred)\n",
    "        \n",
    "        \n",
    "def search_report (iteration_results, true_y, std = False):\n",
    "    \n",
    "    METRICS = {\n",
    "        'accuracy': met.make_scorer(met.accuracy_score),\n",
    "        'precision': met.make_scorer(met.precision_score),\n",
    "        'sensitivity': met.make_scorer(met.recall_score),\n",
    "        'specificity': met.make_scorer(met.recall_score,pos_label = 0),\n",
    "        'f1': met.make_scorer(met.f1_score),\n",
    "        'roc_auc': met.make_scorer(met.roc_auc_score),\n",
    "        \"MCC\" : met.make_scorer(met.matthews_corrcoef)\n",
    "    }\n",
    "        \n",
    "    columns = [\"Hyperparameter Result\"]\n",
    "    for k,_ in METRICS.items():\n",
    "        if std:\n",
    "            columns.append(k + \" std\")\n",
    "        else: \n",
    "            columns.append(k + \" mean\")\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    rows_list = []\n",
    "    \n",
    "    for hp, preds in iteration_results[0].items():\n",
    "        results = { \"Hyperparameter Result\" : hp}\n",
    "        predictions = []\n",
    "        for iteration_result in iteration_results:\n",
    "            predictions.append(iteration_result[hp])\n",
    "                \n",
    "        for k,_ in METRICS.items():\n",
    "            metric_results = []\n",
    "            for prediction in predictions:\n",
    "                metric_results.append(scorer_helper_function(true_y, prediction, k))\n",
    "                     \n",
    "            if std:\n",
    "                results[k + \" std\"] = np.std(metric_results)\n",
    "            else:\n",
    "                results[k + \" mean\"] = np.mean(metric_results)\n",
    "            \n",
    "        rows_list.append(results)\n",
    "        \n",
    "    results = df.append(pd.DataFrame(rows_list), sort = False)\n",
    "            \n",
    "    display(results.round(3)) \n",
    "    \n",
    "    if not std:\n",
    "        i = results[\"sensitivity mean\"].argmax()\n",
    "        display(results.iloc[i][\"Hyperparameter Result\"])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we set various parameters for our tuning and results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#How many grid searches are performed per hyperparameter search, used for more stable results\n",
    "ITERATIONS_TUNING = 10\n",
    "\n",
    "#HOW MANY EPOCHS ARE ALLOWED WITHOUT IMPROVEMENT\n",
    "PATIENCE = 100\n",
    "\n",
    "\n",
    "\n",
    "#Run tuning for layersize\n",
    "RUN_LAYERSIZE_TUNING = 0\n",
    "if RUN_LAYERSIZE_TUNING:\n",
    "    LAYER_SIZES = [2,4,6,8,10,12]\n",
    "\n",
    "# Run tuning for optimizer and learning rate\n",
    "RUN_OPTILEARN_TUNING = 0\n",
    "if RUN_OPTILEARN_TUNING:\n",
    "    LAYER_SIZE = 6\n",
    "    LEARNING_RATES = [0.001,0.01,0.1]\n",
    "\n",
    "# Run look at potential overfitting\n",
    "RUN_OVERFITTING_LOOK = 0\n",
    "if RUN_OVERFITTING_LOOK:\n",
    "    LAYER_SIZE = 6\n",
    "    LEARNING_RATE = 0.1\n",
    "\n",
    "# Run dropout layer tuning\n",
    "RUN_DROPOUT_TUNING = 0\n",
    "if RUN_DROPOUT_TUNING:\n",
    "    LAYER_SIZE = 6\n",
    "    LEARNING_RATE = 0.1\n",
    "    DROPOUT_RATES = [0.0,0.1,0.2,0.3,0.4,0.5]\n",
    "\n",
    "# Run number of layers tuning\n",
    "RUN_LAYERS_TUNING = 0\n",
    "if RUN_LAYERS_TUNING:\n",
    "    LAYER_SIZE = 6\n",
    "    LEARNING_RATE = 0.1\n",
    "    DROPOUT_RATE = 0.0\n",
    "\n",
    "# Get final results\n",
    "RUN_FINAL_RESULTS = 0\n",
    "if RUN_FINAL_RESULTS:\n",
    "    LAYER_SIZE = 6\n",
    "    LEARNING_RATE = 0.1\n",
    "    DROPOUT_RATE = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we implement a simple LSTM with one layer and test different layer sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "\n",
    "import keras.optimizers as optimizers\n",
    "\n",
    "if RUN_LAYERSIZE_TUNING:\n",
    "\n",
    "    layer_sizes = LAYER_SIZES\n",
    "    iteration_results = []\n",
    "\n",
    "    for i in range (0,ITERATIONS_TUNING + 1):\n",
    "        validation_predictions_layers = {}\n",
    "        for layer_size in layer_sizes:\n",
    "\n",
    "            model = Sequential (name = \"LSTM\")\n",
    "\n",
    "            model.add(LSTM(layer_size, input_shape=(None, num_of_dims)))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            model.compile(optimizer='rmsprop',\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "            from sklearn.utils import class_weight\n",
    "\n",
    "            train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                             np.unique(train_y_temp),\n",
    "                                                             train_y_temp)\n",
    "\n",
    "\n",
    "            es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "            mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "            cb_list = [es,mc]\n",
    "\n",
    "            epochs = 500\n",
    "\n",
    "            model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                               validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "            model.load_weights('best_model.h5')\n",
    "\n",
    "            predictions = model.predict_generator(data_generator(validation_x, validation_y, 1), steps = num_of_unique_subjects_validation) > 0.5\n",
    "\n",
    "            validation_predictions_layers[\"Layer Size: \" + str(layer_size)] = predictions\n",
    "\n",
    "        iteration_results.append(validation_predictions_layers)\n",
    "\n",
    "    search_report(iteration_results, validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we implement a simple LSTM with one layer and test optimizers and learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "import keras.optimizers as optimizers\n",
    "\n",
    "if RUN_OPTILEARN_TUNING:\n",
    "    learning_rates = LEARNING_RATES\n",
    "    optimizers = [\"adam\", \"rmsprop\", \"sgd\"]\n",
    "    \n",
    "    iteration_results = []\n",
    "\n",
    "    for i in range (0,ITERATIONS_TUNING + 1):\n",
    "        validation_predictions_opti_learn = {}\n",
    "        for optimizer in optimizers:\n",
    "            for learning_rate in learning_rates:\n",
    "\n",
    "                model = Sequential (name = \"LSTM\")\n",
    "\n",
    "                model.add(LSTM(LAYER_SIZE, input_shape=(None, num_of_dims)))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "                if optimizer == \"adam\":\n",
    "                    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "                elif optimizer == \"rmsprop\":\n",
    "                    opt = keras.optimizers.RMSprop(learning_rate=learning_rate)\n",
    "                else:\n",
    "                    opt = keras.optimizers.SGD(learning_rate=learning_rate)\n",
    "\n",
    "                model.compile(optimizer=opt,\n",
    "                              loss='binary_crossentropy',\n",
    "                              metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "\n",
    "                from sklearn.utils import class_weight\n",
    "\n",
    "                train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "                class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                                 np.unique(train_y_temp),\n",
    "                                                                 train_y_temp)\n",
    "\n",
    "\n",
    "                es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "                mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "                cb_list = [es,mc]\n",
    "\n",
    "                epochs = 500\n",
    "\n",
    "                model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                                   validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "                model.load_weights('best_model.h5')\n",
    "\n",
    "                predictions = model.predict_generator(data_generator(validation_x, validation_y, 1), steps = num_of_unique_subjects_validation) > 0.5\n",
    "\n",
    "                validation_predictions_opti_learn[\"Optimizer: \" + optimizer + \" and learning rate: \" + str(learning_rate)] = predictions\n",
    "                \n",
    "            iteration_results.append(validation_predictions_opti_learn)\n",
    "\n",
    "    search_report(iteration_results, validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We take a look at current model and see if it has an overfitting problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "import keras.optimizers as optimizers\n",
    "\n",
    "if RUN_OVERFITTING_LOOK:\n",
    "    \n",
    "    iteration_results_train = []\n",
    "    iteration_results_validation = []\n",
    "\n",
    "    for i in range (0,ITERATIONS_TUNING + 1):\n",
    "        \n",
    "        model = Sequential (name = \"LSTM\")\n",
    "\n",
    "        model.add(LSTM(LAYER_SIZE, input_shape=(None, num_of_dims)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "        model.compile(optimizer=opt,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "\n",
    "        from sklearn.utils import class_weight\n",
    "\n",
    "        train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                         np.unique(train_y_temp),\n",
    "                                                         train_y_temp)\n",
    "\n",
    "\n",
    "        es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "        mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "        cb_list = [es,mc]\n",
    "\n",
    "        epochs = 500\n",
    "\n",
    "        model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                           validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "        model.load_weights('best_model.h5')\n",
    "\n",
    "        predictions_train = model.predict_generator(data_generator(train_x, train_y, 1), steps = num_of_unique_subjects_train) > 0.5\n",
    "        iteration_results_train.append({\"training_results\" : predictions_train})\n",
    "        predictions_validation = model.predict_generator(data_generator(validation_x, validation_y, 1), steps = num_of_unique_subjects_validation) > 0.5\n",
    "        iteration_results_validation.append({\"validation_results\" : predictions_validation})\n",
    "\n",
    "    \n",
    "    \n",
    "    search_report(iteration_results_train, train_y)\n",
    "    search_report(iteration_results_validation, validation_y)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We implement a dropout layer between the input-layer and the LSTM-layer test different dropout rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "import keras.optimizers as optimizers\n",
    "\n",
    "if RUN_DROPOUT_TUNING:\n",
    "    \n",
    "    iteration_results = []\n",
    "\n",
    "    for i in range (0,ITERATIONS_TUNING + 1):\n",
    "\n",
    "        validation_predictions_dropout = {}\n",
    "\n",
    "        for dropout_rate in DROPOUT_RATES:\n",
    "\n",
    "            model = Sequential (name = \"LSTM\")\n",
    "\n",
    "            model.add(LSTM(LAYER_SIZE, dropout= dropout_rate, input_shape=(None, num_of_dims)))\n",
    "            model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "            model.compile(optimizer=opt,\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "\n",
    "            from sklearn.utils import class_weight\n",
    "\n",
    "            train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                             np.unique(train_y_temp),\n",
    "                                                             train_y_temp)\n",
    "\n",
    "\n",
    "            es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "            mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "            cb_list = [es,mc]\n",
    "\n",
    "            epochs = 500\n",
    "\n",
    "            model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                               validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "            model.load_weights('best_model.h5')\n",
    "\n",
    "            predictions = model.predict_generator(data_generator(validation_x, validation_y, 1), steps = num_of_unique_subjects_validation) > 0.5\n",
    "\n",
    "            validation_predictions_dropout[\"Dropout_rate: \" + str(dropout_rate)] = predictions\n",
    "            \n",
    "        iteration_results.append(validation_predictions_dropout)\n",
    "\n",
    "    search_report(iteration_results, validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finally we try stacking additional LSTM-layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "import keras.optimizers as optimizers\n",
    "\n",
    "if RUN_LAYERS_TUNING:\n",
    "\n",
    "    iteration_results = []\n",
    "\n",
    "    for i in range (0,ITERATIONS_TUNING + 1):\n",
    "\n",
    "        validation_predictions_layers = {}\n",
    "\n",
    "        for layers in range(1,4):\n",
    "\n",
    "            model = Sequential (name = \"LSTM\")\n",
    "\n",
    "            if layers == 1:\n",
    "                model.add(LSTM(LAYER_SIZE, dropout = DROPOUT_RATE, input_shape=(None, num_of_dims)))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            if layers == 2:\n",
    "                model.add(LSTM(LAYER_SIZE, dropout = DROPOUT_RATE, return_sequences = True, input_shape=(None, num_of_dims)))\n",
    "                model.add(LSTM(LAYER_SIZE))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            if layers == 3:\n",
    "                model.add(LSTM(LAYER_SIZE, dropout = DROPOUT_RATE, return_sequences = True, input_shape=(None, num_of_dims)))\n",
    "                model.add(LSTM(LAYER_SIZE, return_sequences = True))\n",
    "                model.add(LSTM(LAYER_SIZE))\n",
    "                model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "            opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "            model.compile(optimizer=opt,\n",
    "                          loss='binary_crossentropy',\n",
    "                          metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "\n",
    "            from sklearn.utils import class_weight\n",
    "\n",
    "            train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "            class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                             np.unique(train_y_temp),\n",
    "                                                             train_y_temp)\n",
    "\n",
    "\n",
    "            es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "            mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "            cb_list = [es,mc]\n",
    "\n",
    "            epochs = 500\n",
    "\n",
    "            model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                               validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "            model.load_weights('best_model.h5')\n",
    "\n",
    "            predictions = model.predict_generator(data_generator(validation_x, validation_y, 1), steps = num_of_unique_subjects_validation) > 0.5\n",
    "\n",
    "            validation_predictions_layers[\"LSTM-Layers: \" + str(layers)] = predictions\n",
    "        \n",
    "        iteration_results.append(validation_predictions_layers)\n",
    "\n",
    "    search_report(iteration_results, validation_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell we look at final results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "import keras.optimizers as optimizers\n",
    "\n",
    "if RUN_FINAL_RESULTS:\n",
    "\n",
    "    iteration_results_train = []\n",
    "    iteration_results_validation = []\n",
    "    iteration_results_test = []\n",
    "\n",
    "    for i in range (0,ITERATIONS_TUNING + 1):\n",
    "\n",
    "        model = Sequential (name = \"LSTM\")\n",
    "\n",
    "        model.add(LSTM(LAYER_SIZE, dropout = DROPOUT_RATE, input_shape=(None, num_of_dims)))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "        opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "        model.compile(optimizer=opt,\n",
    "                      loss='binary_crossentropy',\n",
    "                      metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "\n",
    "        from sklearn.utils import class_weight\n",
    "\n",
    "        train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "        class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                         np.unique(train_y_temp),\n",
    "                                                         train_y_temp)\n",
    "\n",
    "\n",
    "        es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "        mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "        cb_list = [es,mc]\n",
    "\n",
    "        epochs = 500\n",
    "\n",
    "        model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                           validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "        model.load_weights('best_model.h5')\n",
    "\n",
    "        predictions_train = model.predict_generator(data_generator(train_x, train_y, 1), steps = num_of_unique_subjects_train) > 0.5\n",
    "        predictions_validation = model.predict_generator(data_generator(validation_x, validation_y, 1), steps = num_of_unique_subjects_validation) > 0.5      \n",
    "        predictions_test = model.predict_generator(data_generator(test_x, test_y, 1), steps = num_of_unique_subjects_test) > 0.5     \n",
    "        \n",
    "        iteration_results_train.append({\"Train results: \" : predictions_train})\n",
    "        iteration_results_validation.append({\"Validation results: \" : predictions_validation})\n",
    "        iteration_results_test.append({\"Test results: \" : predictions_test})\n",
    "\n",
    "    search_report(iteration_results_train, train_y)        \n",
    "    search_report(iteration_results_train, train_y, std = True)\n",
    "    search_report(iteration_results_validation, validation_y)  \n",
    "    search_report(iteration_results_validation, validation_y, std = True)\n",
    "    search_report(iteration_results_test, test_y)\n",
    "    search_report(iteration_results_test, test_y, std = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell we define a function for plotting sensitivity vs year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras.metrics as met\n",
    "\n",
    "def plot_sensitivity_by_year (FP_results):\n",
    "    \n",
    "    event_id_to_years = {\n",
    "    \"BL\" : \"Baseline\",\n",
    "    \"V04\": \"1-Year\",\n",
    "    \"V06\": \"2-Year\",\n",
    "    \"V08\": \"3-Year\",\n",
    "    \"V10\": \"4-Year\",\n",
    "    \"V12\": \"5-Year\",\n",
    "    \"V13\": \"6-Year\",\n",
    "    \"V14\": \"7-Year\",\n",
    "    \"V15\": \"8-Year\"   \n",
    "    }\n",
    "        \n",
    "    FP_ratio = {}\n",
    "    FP_total = {}\n",
    "        \n",
    "    for event_id, year in event_id_to_years.items():\n",
    "        \n",
    "        correct = np.sum(FP_results.loc[FP_results.FP_EVENT_ID == event_id, \"results\"])\n",
    "        total = FP_results.loc[FP_results.FP_EVENT_ID == event_id, \"results\"].size\n",
    "        \n",
    "        ratio = 0\n",
    "        if total != 0:\n",
    "            ratio = correct/total\n",
    "            \n",
    "        \n",
    "        FP_ratio [year] = ratio\n",
    "        FP_total [year] = total\n",
    "   \n",
    "    fig, axes = pyplot.subplots(nrows=1, ncols=2, figsize=(18, 5))\n",
    "       \n",
    "    x1, y1 = zip(*FP_ratio.items())\n",
    "    axes[0].set_ylabel(\"Sensitivity\")\n",
    "    axes[0].set_xlabel(\"Year\")\n",
    "    axes[0].bar(x1,y1, color = 'g')\n",
    "    \n",
    "    x2, y2 = zip(*FP_total.items())\n",
    "    axes[1].set_ylim (0,16)\n",
    "    axes[1].set_ylabel(\"Positive Subjects\")\n",
    "    axes[1].set_xlabel(\"Year\")\n",
    "    axes[1].bar(x2,y2, color = 'm')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell we plot sensitivity vs year, confusion matrix and roc curves for final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hyperparameter Result</th>\n",
       "      <th>accuracy mean</th>\n",
       "      <th>precision mean</th>\n",
       "      <th>sensitivity mean</th>\n",
       "      <th>specificity mean</th>\n",
       "      <th>f1 mean</th>\n",
       "      <th>roc_auc mean</th>\n",
       "      <th>MCC mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Test results:</td>\n",
       "      <td>0.662</td>\n",
       "      <td>0.385</td>\n",
       "      <td>0.476</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.426</td>\n",
       "      <td>0.603</td>\n",
       "      <td>0.193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Hyperparameter Result  accuracy mean  precision mean  sensitivity mean  \\\n",
       "0        Test results:           0.662           0.385             0.476   \n",
       "\n",
       "   specificity mean  f1 mean  roc_auc mean  MCC mean  \n",
       "0             0.729    0.426         0.603     0.193  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'Test results: '"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity by year: Test\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[43, 16],\n",
       "       [11, 10]], dtype=int64)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1296x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from keras.models import Sequential \n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "\n",
    "from keras.callbacks.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import keras.metrics\n",
    "import keras.optimizers as optimizers\n",
    "from matplotlib import pyplot\n",
    "import sklearn.metrics as met\n",
    "\n",
    "if RUN_FINAL_RESULTS:\n",
    "    LAYER_SIZE = 6\n",
    "    LEARNING_RATE = 0.1\n",
    "    DROPOUT_RATE = 0.0\n",
    "\n",
    "    model = Sequential (name = \"LSTM\")\n",
    "\n",
    "    model.add(LSTM(LAYER_SIZE, dropout = DROPOUT_RATE, input_shape=(None, num_of_dims)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    opt = keras.optimizers.Adam(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    model.compile(optimizer=opt,\n",
    "                  loss='binary_crossentropy',\n",
    "                  metrics=['accuracy',keras.metrics.Recall(name = \"sensitivity\")])\n",
    "\n",
    "\n",
    "    from sklearn.utils import class_weight\n",
    "\n",
    "    train_y_temp = [y.item() for y in train_y]\n",
    "\n",
    "    class_weights = class_weight.compute_class_weight('balanced',\n",
    "                                                     np.unique(train_y_temp),\n",
    "                                                     train_y_temp)\n",
    "\n",
    "\n",
    "    es = EarlyStopping(monitor='val_sensitivity', mode = 'max', verbose = 0, patience = PATIENCE)\n",
    "    mc = ModelCheckpoint('best_model.h5', monitor = 'val_sensitivity', mode = 'max', save_best_only = True, verbose = 0, save_weights_only= True)\n",
    "\n",
    "    cb_list = [es,mc]\n",
    "\n",
    "    epochs = 500\n",
    "\n",
    "    model.fit_generator(data_generator(train_x,train_y, epochs), steps_per_epoch = num_of_unique_subjects_train, epochs = epochs, verbose = 0, class_weight=class_weights, \\\n",
    "                       validation_data = data_generator(validation_x,validation_y, epochs), validation_steps= num_of_unique_subjects_validation, callbacks = cb_list)\n",
    "\n",
    "    model.load_weights('best_model.h5')\n",
    "\n",
    "    predictions_test = model.predict_generator(data_generator(test_x, test_y, 1), steps = num_of_unique_subjects_test) > 0.5     \n",
    "    iteration_results_test = [{\"Test results: \" : predictions_test}]\n",
    "\n",
    "    search_report(iteration_results_test, test_y)\n",
    "\n",
    "    temp_test_FP = test_FP.copy()\n",
    "    temp_test_FP ['results'] = predictions_test\n",
    "    print(\"Sensitivity by year: Test\")        \n",
    "    plot_sensitivity_by_year(temp_test_FP)\n",
    "\n",
    "    display(met.confusion_matrix(test_y, predictions_test))\n",
    "\n",
    "    fpr, tpr, tresholds = met.roc_curve (test_y, predictions_test)\n",
    "    roc_auc = met.roc_auc_score(test_y,predictions_test)\n",
    "\n",
    "    # Code inspired by https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    pyplot.figure()\n",
    "    lw = 2\n",
    "    pyplot.plot(fpr, tpr, color='darkorange',\n",
    "             lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
    "    pyplot.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "    pyplot.xlim([0.0, 1.0])\n",
    "    pyplot.ylim([0.0, 1.05])\n",
    "    pyplot.xlabel('False Positive Rate')\n",
    "    pyplot.ylabel('True Positive Rate')\n",
    "    pyplot.legend(loc=\"lower right\")\n",
    "    pyplot.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
