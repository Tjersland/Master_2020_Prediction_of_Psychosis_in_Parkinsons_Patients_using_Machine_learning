{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Input the directory where your joined_data.csv is located \n",
    "#os.chdir('C:/Users/Trond/Documents/Master 2020/Processed data')\n",
    "os.chdir('C:/Users/Briggstone/Documents/Master 2020/Processed data')\n",
    "#os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data')\n",
    "\n",
    "#Where you want the csv file of the merged data to be placed\n",
    "output_filepath = 'C:/Users/Briggstone/Documents/Master 2020/Processed data'\n",
    "#output_filepath = 'C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data'\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn import svm\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our training data, convert HALL into HALL_EVER and select only BL observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "temptrain = pd.DataFrame(train.PATNO.unique(), columns = [\"PATNO\"])\n",
    "\n",
    "HALL_EVER = []\n",
    "for id in train.PATNO.unique():\n",
    "    if train.loc[(train.PATNO == id) & (train.HALL == 1), \"HALL\"].empty:\n",
    "        HALL_EVER.append(0)\n",
    "    else:\n",
    "        HALL_EVER.append(1)\n",
    "\n",
    "temptrain[\"HALL_EVER\"] = HALL_EVER\n",
    "train.drop(\"HALL\", axis = 1, inplace = True)\n",
    "train = train.merge(temptrain, how = \"inner\", on = \"PATNO\")\n",
    "\n",
    "#Selecting only Baseline observations\n",
    "train = train.loc[train.EVENT_ID == \"BL\", :]\n",
    "\n",
    "#We can then safely drop EVENT_ID\n",
    "train.drop(\"EVENT_ID\", axis = 1, inplace = True)\n",
    "\n",
    "# We form Y\n",
    "Y = train.pop(\"HALL_EVER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(293, 22)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we apply random forest and boosted trees from XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   train-error-mean  train-error-std  train-auc-mean  train-auc-std  \\\n",
      "0          0.152051         0.017769        0.946971       0.011634   \n",
      "\n",
      "   test-error-mean  test-error-std  test-auc-mean  test-auc-std  \n",
      "0         0.262529         0.08896       0.615074      0.163178  \n",
      "   train-error-mean  train-error-std  train-auc-mean  train-auc-std  \\\n",
      "0          0.153959         0.012317        0.861563       0.030197   \n",
      "1          0.122865         0.012582        0.927259       0.022643   \n",
      "2          0.105042         0.012446        0.961868       0.010231   \n",
      "3          0.086846         0.014462        0.979356       0.007951   \n",
      "4          0.068273         0.012770        0.990426       0.004074   \n",
      "5          0.053104         0.015115        0.994661       0.002900   \n",
      "6          0.040589         0.012393        0.998135       0.001181   \n",
      "7          0.030343         0.007793        0.999218       0.000688   \n",
      "8          0.021623         0.007803        0.999648       0.000392   \n",
      "9          0.017071         0.009186        0.999891       0.000118   \n",
      "\n",
      "   test-error-mean  test-error-std  test-auc-mean  test-auc-std  \n",
      "0         0.341149        0.100260       0.590002      0.144189  \n",
      "1         0.299770        0.091043       0.552457      0.143577  \n",
      "2         0.313908        0.086283       0.553570      0.136837  \n",
      "3         0.290115        0.089973       0.576577      0.148000  \n",
      "4         0.269425        0.103126       0.611583      0.134720  \n",
      "5         0.290000        0.098537       0.603074      0.135890  \n",
      "6         0.296667        0.081896       0.613756      0.130620  \n",
      "7         0.289885        0.094418       0.613171      0.108393  \n",
      "8         0.286437        0.083535       0.609918      0.117989  \n",
      "9         0.279655        0.081760       0.621680      0.118107  \n"
     ]
    }
   ],
   "source": [
    "dtrain = xgb.DMatrix(train, label = Y)\n",
    "\n",
    "\n",
    "#Random Forest\n",
    "params = {\n",
    "  'colsample_bynode': 0.8,\n",
    "  'learning_rate': 1,\n",
    "  'max_depth': 5,\n",
    "  'num_parallel_tree': 100,\n",
    "  'objective': 'binary:logistic',\n",
    "  'subsample': 0.8,\n",
    "  'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "cv_results_RF = xgb.cv(params, dtrain = dtrain, num_boost_round=1, nfold = 10, as_pandas = True, seed = 1, metrics = [\"error\", \"auc\"])\n",
    "print(cv_results_RF)\n",
    "\n",
    "\n",
    "#Boosted trees\n",
    "params = {\n",
    "  'objective': 'binary:logistic',\n",
    "  'tree_method': 'gpu_hist'\n",
    "}\n",
    "\n",
    "cv_results_BT = xgb.cv(params, dtrain = dtrain, num_boost_round=10, nfold = 10, as_pandas = True, seed = 1, metrics = [\"error\", \"auc\"])\n",
    "print(cv_results_BT)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we apply SVM from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.59090909, 0.49431818, 0.40340909, 0.45238095, 0.49404762,\n",
       "       0.46428571, 0.60714286, 0.45833333, 0.33333333, 0.29761905])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf1 = svm.SVC(random_state=0, gamma='auto', kernel='rbf')\n",
    "roc_auc1 = cross_val_score(clf1, train, Y, cv=10, scoring='roc_auc')\n",
    "roc_auc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.73333333, 0.73333333, 0.63333333, 0.68965517, 0.72413793,\n",
       "       0.68965517, 0.72413793, 0.72413793, 0.68965517, 0.72413793])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy1 = cross_val_score(clf1, train, Y, cv=10, scoring='accuracy')\n",
    "accuracy1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.65909091, 0.63068182, 0.57386364, 0.5       , 0.57738095,\n",
       "       0.70238095, 0.72619048, 0.57738095, 0.76190476, 0.66666667])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf2 = svm.SVC(random_state=0, gamma='auto', kernel='linear')\n",
    "roc_auc2 = cross_val_score(clf2, train, Y, cv=10, scoring='roc_auc')\n",
    "roc_auc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.66666667, 0.73333333, 0.7       , 0.65517241, 0.75862069,\n",
       "       0.75862069, 0.79310345, 0.68965517, 0.79310345, 0.75862069])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy2 = cross_val_score(clf2, train, Y, cv=10, scoring='accuracy')\n",
    "accuracy2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
