{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Non deep learning models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "Polish code\n",
    "\n",
    "Write up a tuning guide to our different models/ link to api \n",
    "\n",
    "Perhaps eliminate Random Forest as is it boosted trees run with a specific parameter set\n",
    "Seems to always give worse results than boosted and might therefore be redundant\n",
    "\n",
    "add safety for overwriting (final results left)\n",
    "\n",
    "add show p values for logistic regression (on hold for now, sklearn does not support this natively)\n",
    "\n",
    "add final results code with test data\n",
    "\n",
    "look into statistical means of determining if the difference in results between two approaches are significant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Input the directory where your joined_data.csv is located \n",
    "#os.chdir('C:/Users/Trond/Documents/Master 2020/Processed data')\n",
    "os.chdir('C:/Users/Briggstone/Documents/Master 2020/Processed data')\n",
    "#os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data')\n",
    "\n",
    "#Where you want the csv file of the merged data to be placed\n",
    "output_filepath = 'C:/Users/Briggstone/Documents/Master 2020/Processed data'\n",
    "#output_filepath = 'C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data'\n",
    "\n",
    "from matplotlib import pyplot\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import metrics as met\n",
    "from scipy import stats\n",
    "import json\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Initial flags and Options that are constant for all models\n",
    "\"\"\"\n",
    "#Here we set a seed so that our random search produce the same result \n",
    "np.random.seed(31415)\n",
    "\n",
    "# Here we create a scoring dictionary which defines the metrics we report on in cross validation\n",
    "scoring = {\n",
    "    'accuracy': met.make_scorer(met.accuracy_score),\n",
    "    'precision': met.make_scorer(met.precision_score),\n",
    "    'sensitivity': met.make_scorer(met.recall_score),\n",
    "    'specificity': met.make_scorer(met.recall_score,pos_label = 0),\n",
    "    'f1': met.make_scorer(met.f1_score),\n",
    "    'roc_auc': met.make_scorer(met.roc_auc_score),\n",
    "    \"MCC\" : met.make_scorer(met.matthews_corrcoef)\n",
    "}\n",
    "\n",
    "# This is the metric we seek to optimise through tuning\n",
    "refit = \"MCC\"\n",
    "\n",
    "# Which folder of preprocessed data we want to use\n",
    "FOLDER_NAME = \"example\"\n",
    "\n",
    "#Whether to print information about the percentage of positive cases in our train and test sets\n",
    "POSITIVE_CASES_PRINT = 1\n",
    "\n",
    "#Use this to set the number of CPU threads used for cross validation and tuning\n",
    "#CV and tuning can be very cpu intensive and if your cpu runs hot, its advised to not run all cores, though the code will take longer to run\n",
    "#I crashed my computer to blue screen when running cpu at 100% for a period, not fun. My computer is a bit unstable due to overclocking though :P\n",
    "\n",
    "CV_TUNING_N_CORES = 4\n",
    "\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "\n",
    "#Just to stop \\n being printed out due to the open strings\n",
    "clear = 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our training data and drop PATNO and SMOTE helper colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(The number of subjects, number of features) in training set (283, 92)\n",
      "Number of patients which hallucinates eventually in training set is  65.0  which is  0.22968197879858657  percent of patients\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(FOLDER_NAME + '/train.csv')\n",
    "\n",
    "#We read our SMOTE helper column into a variable and then drop it\n",
    "SAMPLING = train.SAMPLING.values[0]\n",
    "train.drop([\"SAMPLING\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# We drop PATNO\n",
    "train.drop([\"PATNO\"], axis = 1, inplace = True)\n",
    "\n",
    "\n",
    "# We form Y\n",
    "train_Y = train.pop(\"HALL\")\n",
    "\n",
    "\n",
    "\n",
    "if POSITIVE_CASES_PRINT:\n",
    "    print(\"(The number of subjects, number of features) in training set\", train.shape)\n",
    "    print(\"Number of patients which hallucinates eventually in training set is \",  sum(train_Y), \" which is \", sum(train_Y)/ (train_Y.size), \" percent of patients\")\n",
    "\n",
    "#Important for xgboost class weight balancing\n",
    "num_pos_samples = sum(train_Y)\n",
    "num_neg_samples = train_Y.size - num_pos_samples\n",
    "pos_weights_scale = num_neg_samples / num_pos_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our test data (if flag is set) and drop PATNO and SMOTE helper columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(The number of subjects, number of features) in test set (73, 92)\n",
      "Number of patients which hallucinates eventually in test set is  18.0  which is  0.2465753424657534  percent of patients\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(FOLDER_NAME + '/test.csv')\n",
    "\n",
    "# We drop PATNO\n",
    "test.drop([\"PATNO\"], axis = 1, inplace = True)\n",
    "\n",
    "# We form Y\n",
    "test_Y = test.pop(\"HALL\")\n",
    "\n",
    "if POSITIVE_CASES_PRINT:\n",
    "    print(\"(The number of subjects, number of features) in test set\", test.shape)\n",
    "    print(\"Number of patients which hallucinates eventually in test set is \",  sum(test_Y), \" which is \", sum(test_Y)/ (test_Y.size), \" percent of patients\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define our sampling (SMOTE currently) functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn as imbl\n",
    "\n",
    "def over_sampling(model, X):\n",
    "    \n",
    "    categorical_columns = []\n",
    "    \n",
    "    for c in X.columns:\n",
    "        if \"C_\" in c:\n",
    "            categorical_columns.append(c)\n",
    "            \n",
    "    categorical_columns = [X.columns.get_loc(c) for c in categorical_columns]\n",
    "\n",
    "    pipeline = imbl.pipeline.make_pipeline(imbl.over_sampling.SMOTENC(categorical_columns, sampling_strategy = 1),\n",
    "                                          model)\n",
    "    \n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define a small function for overwrite protection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def overwrite_protection(path_string):\n",
    "    \n",
    "    file_name_index = path_string.rfind(\"/\")\n",
    "    \n",
    "    #Overwrite protection\n",
    "    if os.path.exists(path_string):        \n",
    "        print(\"File already exists, are you sure you want to overwrite \", path_string[file_name_index + 1:], \" in the folder \", path_string[:file_name_index], \"?\" )\n",
    "        i = input(\"Y?:\")\n",
    "\n",
    "        if i != \"Y\":\n",
    "            raise ValueError(\"Y not answered to overwrite, writing to disk cancelled\")\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define general functions for hyperparameter tuning and cross validation using sklearn functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "'''\n",
    "metrics from sklearn that we can put into scoring variable:\n",
    "‘accuracy’\n",
    "‘balanced_accuracy’\n",
    "‘average_precision’\n",
    "‘neg_brier_score’\n",
    "‘f1’\n",
    "‘neg_log_loss’\n",
    "‘precision’ etc.\n",
    "‘recall’ etc.\n",
    "‘jaccard’ etc.\n",
    "‘roc_auc’\n",
    "'''\n",
    "def randomized_tuning (X,Y, model, param_dist, k_folds, n_iter, scoring_metrics, scoring_refit, sampling):\n",
    "    '''\n",
    "    model should be a XGBClassifier or sklearn classifier \n",
    "    param_dist can look like this, remember that it a randomized search through distributions, not a grid search:\n",
    "    param_dist = {'n_estimators': stats.randint(150, 500),\n",
    "              'learning_rate': stats.uniform(0.01, 0.07),\n",
    "              'subsample': stats.uniform(0.3, 0.7),\n",
    "              'max_depth': [3, 4, 5, 6, 7, 8, 9],\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "              'min_child_weight': [1, 2, 3]\n",
    "             }\n",
    "    k_folds = number of folds in CV\n",
    "    n_iter = number of different random combination of parameters tried. More iterations gives a higher chance of finding the best parameters\n",
    "    scoring metrics = the metrics the search wil report on a the end, example: ['roc_auc', 'f1']\n",
    "    scoring_refit = The single metric that will be used to find a \"best estimator\" at the end,  pick one metric from your scoring metrics list. e.g \"f1\" or \n",
    "    set to False if manually finding best estimator\n",
    "    '''\n",
    "    \n",
    "    if sampling != \"NONE\": \n",
    "        if sampling == \"SMOTE\":\n",
    "            model= over_sampling(model, X)\n",
    "            model_string = model.steps[1][0]\n",
    "            temp_param_dist = copy.deepcopy(param_dist)\n",
    "            param_dist = {model_string + \"__\" + key: param_dist[key] for key in param_dist}\n",
    "                \n",
    "    clf = RandomizedSearchCV(model, param_distributions = param_dist, cv = k_folds, n_iter = n_iter, scoring = scoring_metrics, refit = scoring_refit, \\\n",
    "                             error_score = 0, verbose = 1, n_jobs = CV_TUNING_N_CORES, return_train_score = True)\n",
    "    '''\n",
    "    If scoring_refit is set you can get the best params on that metric by return.best_params_\n",
    "    Manual inspection can be done by pd.DataFrame(return.cv_results_)\n",
    "    '''\n",
    "    params = clf.fit(X,Y).best_params_\n",
    "    if sampling != \"NONE\":\n",
    "        params = {key[key.find('_') + 2:]: params[key] for key in params}\n",
    "        param_dist = temp_param_dist\n",
    "    \n",
    "    for k, v in param_dist.items():\n",
    "        if not isinstance(v, list):\n",
    "            print(\"\\nFor hyperparameter\", k, \" possible interval was : [\" , v.interval(1)[0], \",\", v.interval(1)[1], \"]. The value chosen by RandomSearch is: \", params[k])\n",
    "        else:\n",
    "            values_string = \"[\"\n",
    "            for i in v:\n",
    "                values_string += str(i) + \",\"\n",
    "            values_string += \"]\"\n",
    "            print(\"\\nFor hyperparameter\", k, \" possible values were :\", values_string,  \". The value chosen by GridSearch is: \", params[k])\n",
    "    \n",
    "    print(\"Optimized for \", scoring_refit)    \n",
    "    \n",
    "    return params\n",
    "\n",
    "\n",
    "def grid_tuning(X,Y, model, param_grid, k_folds, scoring_metrics, scoring_refit, sampling):\n",
    "    \n",
    "    if sampling != \"NONE\": \n",
    "        if sampling == \"SMOTE\":\n",
    "            model= over_sampling(model, X)\n",
    "            model_string = model.steps[1][0]\n",
    "            temp_param_grid = copy.deepcopy(param_grid)\n",
    "            param_grid = {model_string + \"__\" + key: param_grid[key] for key in param_grid}\n",
    "            \n",
    "    clf = GridSearchCV(model, param_grid = param_grid, cv = k_folds, scoring = scoring_metrics, refit = scoring_refit, \\\n",
    "                         error_score = 0, verbose = 1, n_jobs = CV_TUNING_N_CORES, return_train_score = True)\n",
    "    \n",
    "    params = clf.fit(X,Y).best_params_\n",
    "    \n",
    "    if sampling != \"NONE\":\n",
    "        params = {key[key.find('_') + 2:]: params[key] for key in params}\n",
    "        param_grid = temp_param_grid\n",
    "        \n",
    "    for k, v in param_grid.items():\n",
    "        values_string = \"[\"\n",
    "        for i in v:\n",
    "            values_string += str(i) + \",\"\n",
    "        values_string += \"]\"\n",
    "        print(\"\\nFor hyperparameter\", k, \" possible values were :\", values_string,  \". The value chosen by GridSearch is: \", params[k])\n",
    "    \n",
    "    print(\"Optimized for \", scoring_refit)\n",
    "    return params\n",
    "\n",
    "\n",
    "def CV_report (model, X, Y, k_folds, scoring, sampling, return_results = False):\n",
    "    \n",
    "    if sampling != \"NONE\": \n",
    "        if sampling == \"SMOTE\":\n",
    "            model= over_sampling(model, X)\n",
    "        \n",
    "    cv_results = cross_validate(model, X, Y, cv= k_folds, scoring= scoring, n_jobs = CV_TUNING_N_CORES,  verbose = 1, return_train_score = True)\n",
    "    \n",
    "    df = pd.DataFrame(columns = [\"Metric\", \"Train mean\", \"Train SD\", \"Test mean\", \"Test SD\"])\n",
    "    rows_list = []\n",
    "    for x in scoring:\n",
    "        score_dict = {}\n",
    "        score_dict[\"Metric\"] = x\n",
    "        score_dict[\"Train mean\"] = np.mean(cv_results[\"train_\" + x])\n",
    "        score_dict[\"Train SD\"] = np.std(cv_results[\"train_\" + x])\n",
    "        score_dict[\"Test mean\"] = np.mean(cv_results[\"test_\" + x])\n",
    "        score_dict[\"Test SD\"] = np.std(cv_results[\"test_\" + x])  \n",
    "        rows_list.append(score_dict)\n",
    "    \n",
    "    results = df.append(pd.DataFrame(rows_list), sort = False)\n",
    "    if return_results:\n",
    "        return results\n",
    "    else:\n",
    "        print(\"\\nCV Report:\")  \n",
    "        print(\"\\n\", results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we set all flags and parameters for Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Flags and Parameters for Logistic Regression\n",
    "'''\n",
    "# 0 = No, 1 = Yes\n",
    "ENABLE_LOGISTIC_REGRESSION = 0\n",
    "\n",
    "#Number of folds to use in CV\n",
    "LOGISTIC_REGRESSION_K_FOLD = 10\n",
    "\n",
    "if ENABLE_LOGISTIC_REGRESSION:\n",
    "    \n",
    "    #Use this for your best CV_results, the txt file can later be used as the parameters for the model used in the final results\n",
    "    # 0 = No, 1 = Yes\n",
    "    LOGISTIC_REGRESSION_SAVE_PARAMS_TO_DISK = 1\n",
    "\n",
    "    if LOGISTIC_REGRESSION_SAVE_PARAMS_TO_DISK:\n",
    "        #Will be used to create a txt file in the same folder as train and test data with the name;\n",
    "        #LOGISTIC_REGRESSION_[FILE_NAME].txt\n",
    "        LOGISTIC_REGRESSION_FILE_NAME = \"bestparams\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  0 = Manual parameters, 1 = RandomSearch, 2 = Gridsearch\n",
    "    LOGISTIC_REGRESSION_TUNING_METHOD = 1\n",
    "    \n",
    "    if LOGISTIC_REGRESSION_TUNING_METHOD == 0:     \n",
    "        \n",
    "        #The parameters that will be used for manual tuning\n",
    "        LOGISTIC_REGRESSION_PARAMS = {\n",
    "            \"solver\" : \"lbfgs\",\n",
    "            \"class_weight\": \"balanced\",\n",
    "            \"n_jobs\": 4,\n",
    "            \"C\" : 5\n",
    "        }\n",
    "    \n",
    "    \n",
    "    elif LOGISTIC_REGRESSION_TUNING_METHOD != 0:\n",
    "        #Use this for parameters that you want to set,but not search through\n",
    "        LOGISTIC_REGRESSION_PARAMS = {\n",
    "            \"solver\" : \"lbfgs\",\n",
    "            \"class_weight\": \"balanced\",\n",
    "            \"n_jobs\": 4\n",
    "        }\n",
    "        \n",
    "        if LOGISTIC_REGRESSION_TUNING_METHOD == 1:\n",
    "            \n",
    "            #Set the number of random searches performed using the distributions provided\n",
    "            #More iterations, likely better results, but worse performance\n",
    "            LOGISTIC_REGRESSION_RANDOMSEARCH_N_ITER = 2\n",
    "            \n",
    "            #Use this to define the distributions to search through in randomsearch\n",
    "            LOGISTIC_REGRESSION_PARAMS_RANDOM_SEARCH = { \n",
    "                'C' : stats.uniform(0.0, 10)\n",
    "                         }\n",
    "            \n",
    "            \n",
    "        elif LOGISTIC_REGRESSION_TUNING_METHOD == 2:\n",
    "            #Use this to define the grid searched through in gridsearch\n",
    "            LOGISTIC_REGRESSION_PARAMS_GRID_SEARCH = { 'C' : [0,0.05,0.1]\n",
    "             }\n",
    "'''\n",
    "'''\n",
    "\n",
    "#Just to stop \\n being printed out due to the open strings\n",
    "clear = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do our logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    1.4s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For hyperparameter C  possible interval was : [ 0.0 , 10.0 ]. The value chosen by RandomSearch is:  6.458186059087547\n",
      "Optimized for  MCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV Report:\n",
      "\n",
      "         Metric  Train mean  Train SD  Test mean   Test SD\n",
      "0     accuracy    0.879872  0.013506   0.707389  0.063726\n",
      "1    precision    0.728993  0.034776   0.380833  0.103148\n",
      "2  sensitivity    0.762478  0.019819   0.395238  0.180450\n",
      "3  specificity    0.914874  0.014121   0.803680  0.085562\n",
      "4           f1    0.745033  0.023877   0.367777  0.125521\n",
      "5      roc_auc    0.838676  0.014177   0.599459  0.082598\n",
      "6          MCC    0.667079  0.032882   0.195015  0.148896\n",
      "File already exists, are you sure you want to overwrite  LOGISTIC_REGRESSION_bestparams.txt  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving hyperparameters to disk\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "if ENABLE_LOGISTIC_REGRESSION:\n",
    "    \n",
    "    if LOGISTIC_REGRESSION_TUNING_METHOD == 0:\n",
    "        \n",
    "        clf_log = LogisticRegression(**LOGISTIC_REGRESSION_PARAMS)\n",
    "        CV_report(clf_log, train, train_Y, LOGISTIC_REGRESSION_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "    if LOGISTIC_REGRESSION_TUNING_METHOD == 1:\n",
    "        \n",
    "        clf_log = LogisticRegression(**LOGISTIC_REGRESSION_PARAMS)\n",
    "        params = randomized_tuning(train,train_Y,clf_log, LOGISTIC_REGRESSION_PARAMS_RANDOM_SEARCH, LOGISTIC_REGRESSION_K_FOLD, \\\n",
    "                                   LOGISTIC_REGRESSION_RANDOMSEARCH_N_ITER, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_log = LogisticRegression(**LOGISTIC_REGRESSION_PARAMS, **params)\n",
    "        CV_report(clf_log, train, train_Y, LOGISTIC_REGRESSION_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "        \n",
    "    if LOGISTIC_REGRESSION_TUNING_METHOD == 2:\n",
    "        \n",
    "        clf_log = LogisticRegression(**LOGISTIC_REGRESSION_PARAMS)\n",
    "        params = grid_tuning(train,train_Y,clf_log, LOGISTIC_REGRESSION_PARAMS_GRID_SEARCH, LOGISTIC_REGRESSION_K_FOLD, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_log = LogisticRegression(**LOGISTIC_REGRESSION_PARAMS, **params)\n",
    "        CV_report(clf_log, train, train_Y, LOGISTIC_REGRESSION_K_FOLD, scoring, SAMPLING)\n",
    "\n",
    "    if LOGISTIC_REGRESSION_SAVE_PARAMS_TO_DISK:\n",
    "        params = clf_log.get_params()\n",
    "        save_string = output_filepath + '/' + FOLDER_NAME + '/LOGISTIC_REGRESSION_' + LOGISTIC_REGRESSION_FILE_NAME + '.txt'\n",
    "        overwrite_protection(save_string)\n",
    "        print(\"\\nSaving hyperparameters to disk\")\n",
    "        with open(save_string, 'w') as f:\n",
    "            json.dump(params, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we set all flags and parameters for Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Flags and Parameters for Support Vector Machines\n",
    "'''\n",
    "# 0 = No, 1 = Yes\n",
    "ENABLE_SVM = 0\n",
    "\n",
    "#Number of folds to use in CV\n",
    "SVM_K_FOLD = 10\n",
    "\n",
    "if ENABLE_SVM:\n",
    "    \n",
    "    #Use this for your best CV_results, the txt file can later be used as the parameters for the model used in the final results\n",
    "    # 0 = No, 1 = Yes\n",
    "    SVM_SAVE_PARAMS_TO_DISK = 1\n",
    "\n",
    "    if SVM_SAVE_PARAMS_TO_DISK:\n",
    "        #Will be used to create a txt file in the same folder as train and test data with the name;\n",
    "        #SVM_[FILE_NAME].txt\n",
    "        SVM_FILE_NAME = \"bestparams\"\n",
    "    \n",
    "    \n",
    "    \n",
    "    #  0 = Manual parameters, 1 = RandomSearch, 2 = Gridsearch\n",
    "    SVM_TUNING_METHOD = 1\n",
    "    \n",
    "    if SVM_TUNING_METHOD == 0:     \n",
    "        \n",
    "        #The parameters that will be used for manual tuning\n",
    "        SVM_PARAMS = {\n",
    "            \"kernel\" : \"linear\",\n",
    "            \"class_weight\": \"balanced\",\n",
    "            \"C\" : 5\n",
    "        }\n",
    "    \n",
    "    \n",
    "    elif SVM_TUNING_METHOD != 0:\n",
    "        #Use this for parameters that you want to set,but not search through\n",
    "        SVM_PARAMS = {\n",
    "            \"class_weight\": \"balanced\",\n",
    "        }\n",
    "        \n",
    "        if SVM_TUNING_METHOD == 1:\n",
    "            \n",
    "            #Set the number of random searches performed using the distributions provided\n",
    "            #More iterations, likely better results, but worse performance\n",
    "            SVM_RANDOMSEARCH_N_ITER = 2\n",
    "            \n",
    "            #Use this to define the distributions to search through in randomsearch\n",
    "            SVM_PARAMS_RANDOM_SEARCH = { \n",
    "                'kernel' : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                'C' : stats.uniform(0.0, 10)\n",
    "                         }\n",
    "            \n",
    "            \n",
    "        elif SVM_TUNING_METHOD == 2:\n",
    "            #Use this to define the grid searched through in gridsearch\n",
    "            SVM_PARAMS_GRID_SEARCH = { \n",
    "                'kernel' : [\"linear\", \"poly\", \"rbf\", \"sigmoid\"],\n",
    "                'C' : [0,0.05,0.1]\n",
    "             }\n",
    "'''\n",
    "'''\n",
    "\n",
    "#Just to stop \\n being printed out due to the open strings\n",
    "clear = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we apply SVM from scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  13 out of  20 | elapsed:    0.5s remaining:    0.2s\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For hyperparameter kernel  possible values were : [linear,poly,rbf,sigmoid,] . The value chosen by GridSearch is:  poly\n",
      "\n",
      "For hyperparameter C  possible interval was : [ 0.0 , 10.0 ]. The value chosen by RandomSearch is:  0.8808905734411399\n",
      "Optimized for  MCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV Report:\n",
      "\n",
      "         Metric  Train mean  Train SD  Test mean   Test SD\n",
      "0     accuracy    0.946605  0.008811   0.759606  0.059310\n",
      "1    precision    0.858218  0.031142   0.482381  0.135612\n",
      "2  sensitivity    0.921333  0.019190   0.480952  0.145920\n",
      "3  specificity    0.954126  0.012070   0.844372  0.061056\n",
      "4           f1    0.888178  0.016875   0.473570  0.136780\n",
      "5      roc_auc    0.937729  0.009423   0.662662  0.079249\n",
      "6          MCC    0.854525  0.021922   0.325502  0.162941\n",
      "File already exists, are you sure you want to overwrite  SVM_bestparams.txt  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving hyperparameters to disk\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "if ENABLE_SVM:\n",
    "    \n",
    "    if SVM_TUNING_METHOD == 0:\n",
    "        \n",
    "        clf_svm = svm.SVC(**SVM_PARAMS)\n",
    "        CV_report(clf_svm, train, train_Y, SVM_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "    if SVM_TUNING_METHOD == 1:\n",
    "        \n",
    "        clf_svm = svm.SVC(**SVM_PARAMS)\n",
    "        params = randomized_tuning(train,train_Y,clf_svm, SVM_PARAMS_RANDOM_SEARCH, SVM_K_FOLD, \\\n",
    "                                   SVM_RANDOMSEARCH_N_ITER, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_svm = svm.SVC(**SVM_PARAMS, **params)\n",
    "        CV_report(clf_svm, train, train_Y, SVM_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "        \n",
    "    if SVM_TUNING_METHOD == 2:\n",
    "        \n",
    "        clf_svm = svm.SVC(**SVM_PARAMS)\n",
    "        params = grid_tuning(train,train_Y,clf_svm, SVM_PARAMS_GRID_SEARCH, SVM_K_FOLD, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_svm = svm.SVC(**SVM_PARAMS, **params)\n",
    "        CV_report(clf_svm, train, train_Y, SVM_K_FOLD, scoring, SAMPLING)\n",
    "\n",
    "    if SVM_SAVE_PARAMS_TO_DISK:\n",
    "        params = clf_svm.get_params()\n",
    "        save_string = output_filepath + '/' + FOLDER_NAME + '/SVM_' + SVM_FILE_NAME + '.txt'\n",
    "        overwrite_protection(save_string)\n",
    "        print(\"\\nSaving hyperparameters to disk\")\n",
    "        with open(save_string, 'w') as f:\n",
    "            json.dump(params, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we set all flags and parameters for the single decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Flags and Parameters for the single decision tree\n",
    "'''\n",
    "# 0 = No, 1 = Yes\n",
    "ENABLE_DECISION_TREE = 0\n",
    "\n",
    "#Number of folds to use in CV\n",
    "DECISION_TREE_K_FOLD = 10\n",
    "\n",
    "if ENABLE_DECISION_TREE:\n",
    "    \n",
    "    #Use this for your best CV_results, the txt file can later be used as the parameters for the model used in the final results\n",
    "    # 0 = No, 1 = Yes\n",
    "    DECISION_TREE_SAVE_PARAMS_TO_DISK = 1\n",
    "\n",
    "    if DECISION_TREE_SAVE_PARAMS_TO_DISK:\n",
    "        #Will be used to create a txt file in the same folder as train and test data with the name;\n",
    "        #DECISION_TREE_[FILE_NAME].txt\n",
    "        DECISION_TREE_FILE_NAME = \"bestparams\"\n",
    "        \n",
    "    #Use this to show a visual presentation of the decision tree built on the training data\n",
    "    # 0 = No, 1 = Yes\n",
    "    DECISION_TREE_PLOT_TREE = 1\n",
    "    \n",
    "    if DECISION_TREE_PLOT_TREE:\n",
    "        \n",
    "        #Use this to limit what parts of the tree is displayed, useful for most trees\n",
    "        #Set to None if you want the full tree\n",
    "        DECISION_TREE_MAX_DEPTH_TO_DISPLAY = 2\n",
    "        \n",
    "        #Use this to save the resulting graph to a png image\n",
    "        # 0 = No, 1 = Yes\n",
    "        DECISION_TREE_SAVE_VISUALIZATION = 1\n",
    "        \n",
    "        if DECISION_TREE_SAVE_VISUALIZATION:\n",
    "            DECISION_TREE_IMAGE_NAME = \"test\"\n",
    "    \n",
    "    \n",
    "    #  0 = Manual parameters, 1 = RandomSearch, 2 = Gridsearch\n",
    "    DECISION_TREE_TUNING_METHOD = 0\n",
    "    \n",
    "    if DECISION_TREE_TUNING_METHOD == 0:     \n",
    "        \n",
    "        #The parameters that will be used for manual tuning\n",
    "        DECISION_TREE_PARAMS = {\n",
    "            \"criterion\" : \"gini\",\n",
    "            \"splitter\" : \"best\",\n",
    "            \"class_weight\" : \"balanced\",\n",
    "            \"ccp_alpha\" : 0.0\n",
    "        }\n",
    "    \n",
    "    \n",
    "    elif DECISION_TREE_TUNING_METHOD != 0:\n",
    "        #Use this for parameters that you want to set,but not search through\n",
    "        DECISION_TREE_PARAMS = {\n",
    "            \"criterion\" : \"gini\",\n",
    "            \"splitter\" : \"best\",\n",
    "            \"class_weight\" : \"balanced\",\n",
    "        }\n",
    "        \n",
    "        if DECISION_TREE_TUNING_METHOD == 1:\n",
    "            \n",
    "            #Set the number of random searches performed using the distributions provided\n",
    "            #More iterations, likely better results, but worse performance\n",
    "            DECISION_TREE_RANDOMSEARCH_N_ITER = 2\n",
    "            \n",
    "            #Use this to define the distributions to search through in randomsearch\n",
    "            DECISION_TREE_PARAMS_RANDOM_SEARCH = { \n",
    "                \"ccp_alpha\" : stats.uniform(0, 1)\n",
    "             }\n",
    "            \n",
    "            \n",
    "        elif DECISION_TREE_TUNING_METHOD == 2:\n",
    "            #Use this to define the grid searched through in gridsearch\n",
    "            DECISION_TREE_PARAMS_GRID_SEARCH = { \n",
    "                \"ccp_alpha\" : [0.1,0.2,0.3,0.4,0.5]\n",
    "             }\n",
    "'''\n",
    "'''\n",
    "\n",
    "#Just to stop \\n being printed out due to the open strings\n",
    "clear = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do a decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV Report:\n",
      "\n",
      "         Metric  Train mean  Train SD  Test mean   Test SD\n",
      "0     accuracy         1.0       0.0   0.699015  0.085696\n",
      "1    precision         1.0       0.0   0.376364  0.169312\n",
      "2  sensitivity         1.0       0.0   0.430952  0.201032\n",
      "3  specificity         1.0       0.0   0.779437  0.098419\n",
      "4           f1         1.0       0.0   0.390179  0.170353\n",
      "5      roc_auc         1.0       0.0   0.605195  0.110419\n",
      "6          MCC         1.0       0.0   0.203791  0.215647\n",
      "File already exists, are you sure you want to overwrite  DECISION_TREE_bestparams.txt  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving hyperparameters to disk\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"401pt\" viewBox=\"0.00 0.00 736.00 401.00\" width=\"736pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 397)\">\n",
       "<title>Tree</title>\n",
       "<polygon fill=\"white\" points=\"-4,4 -4,-397 732,-397 732,4 -4,4\" stroke=\"none\"/>\n",
       "<!-- 0 -->\n",
       "<g class=\"node\" id=\"node1\"><title>0</title>\n",
       "<polygon fill=\"#ffffff\" points=\"416,-393 207,-393 207,-310 416,-310 416,-393\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-377.8\">PD_DURATION_MAX &lt;= 0.369</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-362.8\">gini = 0.5</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-347.8\">samples = 100.0%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-332.8\">value = [0.5, 0.5]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"311.5\" y=\"-317.8\">class = Negative</text>\n",
       "</g>\n",
       "<!-- 1 -->\n",
       "<g class=\"node\" id=\"node2\"><title>1</title>\n",
       "<polygon fill=\"#88c4ef\" points=\"302.5,-274 92.5,-274 92.5,-191 302.5,-191 302.5,-274\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-258.8\">LNSTOT_INTERCEPT &lt;= 1.228</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-243.8\">gini = 0.408</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-228.8\">samples = 36.4%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-213.8\">value = [0.286, 0.714]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"197.5\" y=\"-198.8\">class = Positive</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;1 -->\n",
       "<g class=\"edge\" id=\"edge1\"><title>0-&gt;1</title>\n",
       "<path d=\"M271.948,-309.907C262.929,-300.651 253.265,-290.732 243.986,-281.209\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"246.467,-278.741 236.982,-274.021 241.454,-283.626 246.467,-278.741\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"236.657\" y=\"-295.319\">True</text>\n",
       "</g>\n",
       "<!-- 40 -->\n",
       "<g class=\"node\" id=\"node7\"><title>40</title>\n",
       "<polygon fill=\"#f1b991\" points=\"532,-274 321,-274 321,-191 532,-191 532,-274\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-258.8\">NP1COG_INTERCEPT &lt;= 0.155</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-243.8\">gini = 0.425</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-228.8\">samples = 63.6%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-213.8\">value = [0.693, 0.307]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"426.5\" y=\"-198.8\">class = Negative</text>\n",
       "</g>\n",
       "<!-- 0&#45;&gt;40 -->\n",
       "<g class=\"edge\" id=\"edge6\"><title>0-&gt;40</title>\n",
       "<path d=\"M351.399,-309.907C360.497,-300.651 370.246,-290.732 379.607,-281.209\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"382.158,-283.606 386.672,-274.021 377.166,-278.699 382.158,-283.606\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"386.887\" y=\"-295.32\">False</text>\n",
       "</g>\n",
       "<!-- 2 -->\n",
       "<g class=\"node\" id=\"node3\"><title>2</title>\n",
       "<polygon fill=\"#79bded\" points=\"139,-155 0,-155 0,-72 139,-72 139,-155\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69.5\" y=\"-139.8\">AGE_MIN &lt;= 0.616</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69.5\" y=\"-124.8\">gini = 0.37</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69.5\" y=\"-109.8\">samples = 32.5%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69.5\" y=\"-94.8\">value = [0.245, 0.755]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"69.5\" y=\"-79.8\">class = Positive</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;2 -->\n",
       "<g class=\"edge\" id=\"edge2\"><title>1-&gt;2</title>\n",
       "<path d=\"M153.091,-190.907C142.865,-181.56 131.9,-171.538 121.388,-161.929\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"123.573,-159.184 113.83,-155.021 118.85,-164.351 123.573,-159.184\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 39 -->\n",
       "<g class=\"node\" id=\"node6\"><title>39</title>\n",
       "<polygon fill=\"#e58139\" points=\"269.5,-147.5 157.5,-147.5 157.5,-79.5 269.5,-79.5 269.5,-147.5\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-132.3\">gini = -0.0</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-117.3\">samples = 3.9%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-102.3\">value = [1.0, 0.0]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"213.5\" y=\"-87.3\">class = Negative</text>\n",
       "</g>\n",
       "<!-- 1&#45;&gt;39 -->\n",
       "<g class=\"edge\" id=\"edge5\"><title>1-&gt;39</title>\n",
       "<path d=\"M203.051,-190.907C204.515,-180.204 206.1,-168.615 207.582,-157.776\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"211.077,-158.049 208.964,-147.667 204.142,-157.1 211.077,-158.049\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 3 -->\n",
       "<g class=\"node\" id=\"node4\"><title>3</title>\n",
       "<polygon fill=\"#c0c0c0\" points=\"60.5,-36 6.5,-36 6.5,-0 60.5,-0 60.5,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"33.5\" y=\"-14.3\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;3 -->\n",
       "<g class=\"edge\" id=\"edge3\"><title>2-&gt;3</title>\n",
       "<path d=\"M53.8146,-71.7615C50.4573,-63.0419 46.9907,-54.0385 43.8927,-45.9921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"47.0609,-44.4797 40.2014,-36.4051 40.5284,-46.9949 47.0609,-44.4797\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 32 -->\n",
       "<g class=\"node\" id=\"node5\"><title>32</title>\n",
       "<polygon fill=\"#c0c0c0\" points=\"132.5,-36 78.5,-36 78.5,-0 132.5,-0 132.5,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.5\" y=\"-14.3\">(...)</text>\n",
       "</g>\n",
       "<!-- 2&#45;&gt;32 -->\n",
       "<g class=\"edge\" id=\"edge4\"><title>2-&gt;32</title>\n",
       "<path d=\"M85.1854,-71.7615C88.5427,-63.0419 92.0093,-54.0385 95.1073,-45.9921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"98.4716,-46.9949 98.7986,-36.4051 91.9391,-44.4797 98.4716,-46.9949\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 41 -->\n",
       "<g class=\"node\" id=\"node8\"><title>41</title>\n",
       "<polygon fill=\"#e89151\" points=\"505,-155 318,-155 318,-72 505,-72 505,-155\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-139.8\">SDMTOTAL_MAX &lt;= 2.016</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-124.8\">gini = 0.195</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-109.8\">samples = 39.9%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-94.8\">value = [0.89, 0.11]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"411.5\" y=\"-79.8\">class = Negative</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;41 -->\n",
       "<g class=\"edge\" id=\"edge7\"><title>40-&gt;41</title>\n",
       "<path d=\"M421.296,-190.907C420.225,-182.558 419.086,-173.671 417.977,-165.02\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"421.438,-164.495 416.695,-155.021 414.495,-165.385 421.438,-164.495\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 50 -->\n",
       "<g class=\"node\" id=\"node11\"><title>50</title>\n",
       "<polygon fill=\"#e7f3fc\" points=\"728,-155 523,-155 523,-72 728,-72 728,-155\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625.5\" y=\"-139.8\">MCATOT_DEGREE1 &lt;= -0.237</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625.5\" y=\"-124.8\">gini = 0.498</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625.5\" y=\"-109.8\">samples = 23.7%</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625.5\" y=\"-94.8\">value = [0.467, 0.533]</text>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"625.5\" y=\"-79.8\">class = Positive</text>\n",
       "</g>\n",
       "<!-- 40&#45;&gt;50 -->\n",
       "<g class=\"edge\" id=\"edge10\"><title>40-&gt;50</title>\n",
       "<path d=\"M495.542,-190.907C512.367,-181.016 530.477,-170.368 547.679,-160.254\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"549.733,-163.106 556.58,-155.021 546.186,-157.072 549.733,-163.106\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 42 -->\n",
       "<g class=\"node\" id=\"node9\"><title>42</title>\n",
       "<polygon fill=\"#c0c0c0\" points=\"402.5,-36 348.5,-36 348.5,-0 402.5,-0 402.5,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"375.5\" y=\"-14.3\">(...)</text>\n",
       "</g>\n",
       "<!-- 41&#45;&gt;42 -->\n",
       "<g class=\"edge\" id=\"edge8\"><title>41-&gt;42</title>\n",
       "<path d=\"M395.815,-71.7615C392.457,-63.0419 388.991,-54.0385 385.893,-45.9921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"389.061,-44.4797 382.201,-36.4051 382.528,-46.9949 389.061,-44.4797\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 47 -->\n",
       "<g class=\"node\" id=\"node10\"><title>47</title>\n",
       "<polygon fill=\"#c0c0c0\" points=\"474.5,-36 420.5,-36 420.5,-0 474.5,-0 474.5,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"447.5\" y=\"-14.3\">(...)</text>\n",
       "</g>\n",
       "<!-- 41&#45;&gt;47 -->\n",
       "<g class=\"edge\" id=\"edge9\"><title>41-&gt;47</title>\n",
       "<path d=\"M427.185,-71.7615C430.543,-63.0419 434.009,-54.0385 437.107,-45.9921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"440.472,-46.9949 440.799,-36.4051 433.939,-44.4797 440.472,-46.9949\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 51 -->\n",
       "<g class=\"node\" id=\"node12\"><title>51</title>\n",
       "<polygon fill=\"#c0c0c0\" points=\"616.5,-36 562.5,-36 562.5,-0 616.5,-0 616.5,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"589.5\" y=\"-14.3\">(...)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;51 -->\n",
       "<g class=\"edge\" id=\"edge11\"><title>50-&gt;51</title>\n",
       "<path d=\"M609.815,-71.7615C606.457,-63.0419 602.991,-54.0385 599.893,-45.9921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"603.061,-44.4797 596.201,-36.4051 596.528,-46.9949 603.061,-44.4797\" stroke=\"black\"/>\n",
       "</g>\n",
       "<!-- 56 -->\n",
       "<g class=\"node\" id=\"node13\"><title>56</title>\n",
       "<polygon fill=\"#c0c0c0\" points=\"688.5,-36 634.5,-36 634.5,-0 688.5,-0 688.5,-36\" stroke=\"black\"/>\n",
       "<text font-family=\"Times New Roman,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"661.5\" y=\"-14.3\">(...)</text>\n",
       "</g>\n",
       "<!-- 50&#45;&gt;56 -->\n",
       "<g class=\"edge\" id=\"edge12\"><title>50-&gt;56</title>\n",
       "<path d=\"M641.185,-71.7615C644.543,-63.0419 648.009,-54.0385 651.107,-45.9921\" fill=\"none\" stroke=\"black\"/>\n",
       "<polygon fill=\"black\" points=\"654.472,-46.9949 654.799,-36.4051 647.939,-44.4797 654.472,-46.9949\" stroke=\"black\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, are you sure you want to overwrite  DECISION_TREE_test.pdf  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "\n",
    "if ENABLE_DECISION_TREE:\n",
    "    \n",
    "    if DECISION_TREE_TUNING_METHOD == 0:\n",
    "        \n",
    "        clf_DT = DecisionTreeClassifier(**DECISION_TREE_PARAMS)\n",
    "        CV_report(clf_DT, train, train_Y, DECISION_TREE_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "    if DECISION_TREE_TUNING_METHOD == 1:\n",
    "        \n",
    "        clf_DT = DecisionTreeClassifier(**DECISION_TREE_PARAMS)\n",
    "        params = randomized_tuning(train,train_Y,clf_DT, DECISION_TREE_PARAMS_RANDOM_SEARCH, DECISION_TREE_K_FOLD, \\\n",
    "                                   DECISION_TREE_RANDOMSEARCH_N_ITER, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_DT = DecisionTreeClassifier(**DECISION_TREE_PARAMS, **params)\n",
    "        CV_report(clf_DT, train, train_Y, DECISION_TREE_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "        \n",
    "    if DECISION_TREE_TUNING_METHOD == 2:\n",
    "        \n",
    "        clf_DT = DecisionTreeClassifier(**DECISION_TREE_PARAMS)\n",
    "        params = grid_tuning(train,train_Y,clf_DT, DECISION_TREE_PARAMS_GRID_SEARCH, DECISION_TREE_K_FOLD, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_DT = DecisionTreeClassifier(**DECISION_TREE_PARAMS, **params)\n",
    "        CV_report(clf_DT, train, train_Y, DECISION_TREE_K_FOLD, scoring, SAMPLING)\n",
    "\n",
    "    if DECISION_TREE_SAVE_PARAMS_TO_DISK:\n",
    "        params = clf_DT.get_params()\n",
    "        save_string = output_filepath + '/' + FOLDER_NAME + '/DECISION_TREE_' + DECISION_TREE_FILE_NAME + '.txt'\n",
    "        overwrite_protection(save_string)\n",
    "        print(\"\\nSaving hyperparameters to disk\")\n",
    "        with open(save_string, 'w') as f:\n",
    "            json.dump(params, f) \n",
    "        \n",
    "    if DECISION_TREE_PLOT_TREE:\n",
    "        from IPython.display import SVG\n",
    "        from graphviz import Source\n",
    "        from IPython.display import display\n",
    "        \n",
    "        labels = train.columns\n",
    "        \n",
    "        fit = clf_DT.fit(train,train_Y)\n",
    "        \n",
    "        graph = tree.export_graphviz(fit, out_file=None, feature_names=labels, class_names=['Negative', 'Positive'],filled = True, \\\n",
    "                        max_depth = DECISION_TREE_MAX_DEPTH_TO_DISPLAY, proportion = True)\n",
    "        graph_source = Source(graph)\n",
    "        display(SVG(graph_source.pipe(format='svg')))\n",
    "        \n",
    "        if DECISION_TREE_SAVE_VISUALIZATION:\n",
    "            save_string = output_filepath + '/' + FOLDER_NAME + '/DECISION_TREE_' + DECISION_TREE_IMAGE_NAME + '.pdf'\n",
    "            overwrite_protection(save_string)\n",
    "            save_string = save_string[0:-4]\n",
    "            graph_source.render(save_string) \n",
    "            os.remove(save_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we set all flags and parameters for Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Flags and Parameters for Random Forest\n",
    "'''\n",
    "# 0 = No, 1 = Yes\n",
    "ENABLE_RANDOM_FOREST = 0\n",
    "\n",
    "#Number of folds to use in CV\n",
    "RANDOM_FOREST_K_FOLD = 10\n",
    "\n",
    "if ENABLE_RANDOM_FOREST:\n",
    "    \n",
    "    #Use this for your best CV_results, the txt file can later be used as the parameters for the model used in the final results\n",
    "    # 0 = No, 1 = Yes\n",
    "    RANDOM_FOREST_SAVE_PARAMS_TO_DISK = 1\n",
    "\n",
    "    if RANDOM_FOREST_SAVE_PARAMS_TO_DISK:\n",
    "        #Will be used to create a txt file in the same folder as train and test data with the name;\n",
    "        #RANDOM_FOREST_[FILE_NAME].txt\n",
    "        RANDOM_FOREST_FILE_NAME = \"bestparams\"\n",
    "    \n",
    "    #Use this to show a plot of estimated feature importance found from the trees constructed\n",
    "    # 0 = No, 1 = Yes\n",
    "    RANDOM_FOREST_SHOW_FEATURE_IMPORTANCE = 1\n",
    "    if RANDOM_FOREST_SHOW_FEATURE_IMPORTANCE:\n",
    "        #As the plot quickly becomes impoosible to read if a lot of features are included in the model\n",
    "        RANDOM_FOREST_MAX_NUMBER_OF_FEATURES_TO_SHOW = 15\n",
    "    \n",
    "    #  0 = Manual parameters, 1 = RandomSearch, 2 = Gridsearch\n",
    "    RANDOM_FOREST_TUNING_METHOD = 1\n",
    "    \n",
    "    if RANDOM_FOREST_TUNING_METHOD == 0:     \n",
    "        \n",
    "        #The parameters that will be used for manual tuning\n",
    "        RANDOM_FOREST_PARAMS = {\n",
    "          'colsample_bynode': 0.8,\n",
    "            'n_estimators' : 1,\n",
    "          'learning_rate': 1,\n",
    "          'max_depth': 5,\n",
    "          'num_parallel_tree': 100,\n",
    "          'objective': 'binary:logistic',\n",
    "          'subsample': 0.8,\n",
    "          'scale_pos_weight' : pos_weights_scale\n",
    "        }\n",
    "    \n",
    "    \n",
    "    elif RANDOM_FOREST_TUNING_METHOD != 0:\n",
    "        #Use this for parameters that you want to set,but not search through\n",
    "        RANDOM_FOREST_PARAMS = {\n",
    "            'n_estimators' : 1,\n",
    "            'learning_rate': 1,\n",
    "            'objective': 'binary:logistic',\n",
    "            'scale_pos_weight' : pos_weights_scale\n",
    "        }\n",
    "        \n",
    "        if RANDOM_FOREST_TUNING_METHOD == 1:\n",
    "            \n",
    "            #Set the number of random searches performed using the distributions provided\n",
    "            #More iterations, likely better results, but worse performance\n",
    "            RANDOM_FOREST_RANDOMSEARCH_N_ITER = 2\n",
    "            \n",
    "            #Use this to define the distributions to search through in randomsearch\n",
    "            RANDOM_FOREST_PARAMS_RANDOM_SEARCH = { 'colsample_bynode': stats.uniform(0.5, 0.45),\n",
    "              'max_depth': stats.randint(3,9),\n",
    "              'subsample': stats.uniform(0.3, 0.6),\n",
    "              'num_parallel_tree': stats.randint(50,200), \n",
    "              'max_delta_step' : stats.uniform(0,15)\n",
    "             }\n",
    "            \n",
    "            \n",
    "        elif RANDOM_FOREST_TUNING_METHOD == 2:\n",
    "            #Use this to define the grid searched through in gridsearch\n",
    "            RANDOM_FOREST_PARAMS_GRID_SEARCH = { 'colsample_bynode': [0.5,0.75],\n",
    "              'max_depth': [3, 7],             \n",
    "              'subsample': [0.5,0.75],\n",
    "              'num_parallel_tree': [2,5],\n",
    "              'max_delta_step' : [0,5]\n",
    "             }\n",
    "'''\n",
    "'''\n",
    "\n",
    "#Just to stop \\n being printed out due to the open strings\n",
    "clear = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do random forest from XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 2 candidates, totalling 20 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  20 out of  20 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For hyperparameter colsample_bynode  possible interval was : [ 0.5 , 0.95 ]. The value chosen by RandomSearch is:  0.7394212120896099\n",
      "\n",
      "For hyperparameter max_depth  possible interval was : [ 2.0 , 8.0 ]. The value chosen by RandomSearch is:  5\n",
      "\n",
      "For hyperparameter subsample  possible interval was : [ 0.3 , 0.8999999999999999 ]. The value chosen by RandomSearch is:  0.872578096411045\n",
      "\n",
      "For hyperparameter num_parallel_tree  possible interval was : [ 49.0 , 199.0 ]. The value chosen by RandomSearch is:  159\n",
      "\n",
      "For hyperparameter max_delta_step  possible interval was : [ 0.0 , 15.0 ]. The value chosen by RandomSearch is:  1.2321384694226456\n",
      "Optimized for  MCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    1.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV Report:\n",
      "\n",
      "         Metric  Train mean  Train SD  Test mean   Test SD\n",
      "0     accuracy    0.792671  0.042576   0.603202  0.123865\n",
      "1    precision    0.530677  0.052352   0.338175  0.081780\n",
      "2  sensitivity    1.000000  0.000000   0.621429  0.124835\n",
      "3  specificity    0.730830  0.055388   0.601948  0.174361\n",
      "4           f1    0.691874  0.044329   0.425008  0.070669\n",
      "5      roc_auc    0.865415  0.027694   0.611688  0.078664\n",
      "6          MCC    0.622720  0.054220   0.196162  0.137424\n",
      "File already exists, are you sure you want to overwrite  RANDOM_FOREST_bestparams.txt  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving hyperparameters to disk\n",
      "Plot of feature importance:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "import xgboost as xgb\n",
    "\n",
    "if ENABLE_RANDOM_FOREST:\n",
    "    \n",
    "    if RANDOM_FOREST_TUNING_METHOD == 0:\n",
    "        \n",
    "        clf_RF = XGBClassifier(**RANDOM_FOREST_PARAMS)\n",
    "        CV_report(clf_RF, train, train_Y, RANDOM_FOREST_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "    if RANDOM_FOREST_TUNING_METHOD == 1:\n",
    "        \n",
    "        clf_RF = XGBClassifier(**RANDOM_FOREST_PARAMS)\n",
    "        params = randomized_tuning(train,train_Y,clf_RF, RANDOM_FOREST_PARAMS_RANDOM_SEARCH, RANDOM_FOREST_K_FOLD, \\\n",
    "                                   RANDOM_FOREST_RANDOMSEARCH_N_ITER, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_RF = XGBClassifier(**RANDOM_FOREST_PARAMS, **params)\n",
    "        CV_report(clf_RF, train, train_Y, RANDOM_FOREST_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "        \n",
    "    if RANDOM_FOREST_TUNING_METHOD == 2:\n",
    "        \n",
    "        clf_RF = XGBClassifier(**RANDOM_FOREST_PARAMS)\n",
    "        params = grid_tuning(train,train_Y,clf_RF, RANDOM_FOREST_PARAMS_GRID_SEARCH, RANDOM_FOREST_K_FOLD, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_RF = XGBClassifier(**RANDOM_FOREST_PARAMS, **params)\n",
    "        CV_report(clf_RF, train, train_Y, RANDOM_FOREST_K_FOLD, scoring, SAMPLING)\n",
    "\n",
    "    if RANDOM_FOREST_SAVE_PARAMS_TO_DISK:\n",
    "        params = clf_RF.get_params()\n",
    "        save_string = output_filepath + '/' + FOLDER_NAME + '/RANDOM_FOREST_' + RANDOM_FOREST_FILE_NAME + '.txt'\n",
    "        overwrite_protection(save_string)\n",
    "        print(\"\\nSaving hyperparameters to disk\")\n",
    "        with open(save_string, 'w') as f:\n",
    "            json.dump(params, f)\n",
    "\n",
    "    if RANDOM_FOREST_SHOW_FEATURE_IMPORTANCE:\n",
    "        print(\"Plot of feature importance:\")\n",
    "        xgb.plot_importance(clf_RF.fit(train,train_Y), max_num_features = RANDOM_FOREST_MAX_NUMBER_OF_FEATURES_TO_SHOW)\n",
    "        pyplot.show()  \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we set all flags and parameters for boosted trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Flags and Parameters for boosted trees\n",
    "'''\n",
    "# 0 = No, 1 = Yes\n",
    "ENABLE_BOOSTED_TREES = 0\n",
    "\n",
    "#Number of folds to use in CV\n",
    "BOOSTED_TREES_K_FOLD = 10\n",
    "\n",
    "if ENABLE_BOOSTED_TREES:\n",
    "    \n",
    "    #Use this for your best CV_results, the txt file can later be used as the parameters for the model used in the final results\n",
    "    # 0 = No, 1 = Yes\n",
    "    BOOSTED_TREES_SAVE_PARAMS_TO_DISK = 1\n",
    "\n",
    "    if BOOSTED_TREES_SAVE_PARAMS_TO_DISK:\n",
    "        #Will be used to create a txt file in the same folder as train and test data with the name;\n",
    "        #BOOSTED_TREES_[FILE_NAME].txt\n",
    "        BOOSTED_TREES_FILE_NAME = \"bestparams\"\n",
    "    \n",
    "     #Use this to show a plot of estimated feature importance found from the trees constructed\n",
    "    # 0 = No, 1 = Yes\n",
    "    BOOSTED_TREES_SHOW_FEATURE_IMPORTANCE = 1\n",
    "    if BOOSTED_TREES_SHOW_FEATURE_IMPORTANCE:\n",
    "        #As the plot quickly becomes impoosible to read if a lot of features are included in the model\n",
    "        BOOSTED_TREES_MAX_NUMBER_OF_FEATURES_TO_SHOW = 15\n",
    "    \n",
    "    #  0 = Manual parameters, 1 = RandomSearch, 2 = Gridsearch\n",
    "    BOOSTED_TREES_TUNING_METHOD = 1\n",
    "    \n",
    "    if BOOSTED_TREES_TUNING_METHOD == 0:     \n",
    "        \n",
    "        #The parameters that will be used for manual tuning\n",
    "        BOOSTED_TREES_PARAMS = {\n",
    "            'n_estimators' : 2,\n",
    "            'learning_rate': 1,\n",
    "            'max_depth': 2,\n",
    "            'objective': 'binary:logistic',\n",
    "            'scale_pos_weight':  pos_weights_scale\n",
    "        }\n",
    "    \n",
    "    \n",
    "    elif BOOSTED_TREES_TUNING_METHOD != 0:\n",
    "        #Use this for parameters that you want to set,but not search through\n",
    "        BOOSTED_TREES_PARAMS = {\n",
    "            'objective': 'binary:logistic',\n",
    "            'scale_pos_weight' : pos_weights_scale\n",
    "        }\n",
    "        \n",
    "        if BOOSTED_TREES_TUNING_METHOD == 1:\n",
    "            \n",
    "            #Set the number of random searches performed using the distributions provided\n",
    "            #More iterations, likely better results, but worse performance\n",
    "            BOOSTED_TREES_RANDOMSEARCH_N_ITER = 20\n",
    "            \n",
    "            #Use this to define the distributions to search through in randomsearch\n",
    "            BOOSTED_TREES_PARAMS_RANDOM_SEARCH = {'n_estimators': stats.randint(1, 100),\n",
    "              'learning_rate': stats.uniform(0.01, 0.99),\n",
    "              'subsample': stats.uniform(0.3, 0.7),\n",
    "              'max_depth': stats.randint(3,9),\n",
    "              'colsample_bytree': stats.uniform(0.5, 0.45),\n",
    "              'min_child_weight': stats.randint(1,3),\n",
    "              'max_delta_step' : stats.uniform(0,15),\n",
    "             }\n",
    "            \n",
    "            \n",
    "        elif BOOSTED_TREES_TUNING_METHOD == 2:\n",
    "            #Use this to define the grid searched through in gridsearch\n",
    "            BOOSTED_TREES_PARAMS_GRID_SEARCH = {'n_estimators': [1,50],\n",
    "              'learning_rate': [0.1,0.2],\n",
    "              'subsample': [0.3,0.5],\n",
    "              'max_depth': [3,5],\n",
    "              'colsample_bytree': [0.5,0,7],\n",
    "              'min_child_weight': [1,3],\n",
    "              'max_delta_step' : [5,10],\n",
    "             }\n",
    "'''\n",
    "'''\n",
    "\n",
    "#Just to stop \\n being printed out due to the open strings\n",
    "clear = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do boosted trees from XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 20 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  76 tasks      | elapsed:    3.4s\n",
      "[Parallel(n_jobs=4)]: Done 200 out of 200 | elapsed:   10.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "For hyperparameter n_estimators  possible interval was : [ 0.0 , 99.0 ]. The value chosen by RandomSearch is:  60\n",
      "\n",
      "For hyperparameter learning_rate  possible interval was : [ 0.01 , 1.0 ]. The value chosen by RandomSearch is:  0.17719820599214647\n",
      "\n",
      "For hyperparameter subsample  possible interval was : [ 0.3 , 1.0 ]. The value chosen by RandomSearch is:  0.8731729108666793\n",
      "\n",
      "For hyperparameter max_depth  possible interval was : [ 2.0 , 8.0 ]. The value chosen by RandomSearch is:  4\n",
      "\n",
      "For hyperparameter colsample_bytree  possible interval was : [ 0.5 , 0.95 ]. The value chosen by RandomSearch is:  0.7062751130026329\n",
      "\n",
      "For hyperparameter min_child_weight  possible interval was : [ 0.0 , 2.0 ]. The value chosen by RandomSearch is:  1\n",
      "\n",
      "For hyperparameter max_delta_step  possible interval was : [ 0.0 , 15.0 ]. The value chosen by RandomSearch is:  14.862578070426062\n",
      "Optimized for  MCC\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV Report:\n",
      "\n",
      "         Metric  Train mean  Train SD  Test mean   Test SD\n",
      "0     accuracy    0.999608  0.001176   0.748645  0.067970\n",
      "1    precision    0.998333  0.005000   0.485595  0.106091\n",
      "2  sensitivity    1.000000  0.000000   0.523810  0.101575\n",
      "3  specificity    0.999490  0.001531   0.816667  0.101395\n",
      "4           f1    0.999160  0.002521   0.491026  0.074503\n",
      "5      roc_auc    0.999745  0.000765   0.670238  0.048035\n",
      "6          MCC    0.998910  0.003270   0.337778  0.099942\n",
      "File already exists, are you sure you want to overwrite  BOOSTED_TREES_bestparams.txt  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving hyperparameters to disk\n",
      "Plot of feature importance:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "\n",
    "if ENABLE_BOOSTED_TREES:\n",
    "    \n",
    "    if BOOSTED_TREES_TUNING_METHOD == 0:\n",
    "        \n",
    "        clf_BT = XGBClassifier(**BOOSTED_TREES_PARAMS)\n",
    "        CV_report(clf_BT, train, train_Y, BOOSTED_TREES_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "    if BOOSTED_TREES_TUNING_METHOD == 1:\n",
    "        \n",
    "        clf_BT = XGBClassifier(**BOOSTED_TREES_PARAMS)\n",
    "        params = randomized_tuning(train,train_Y,clf_BT, BOOSTED_TREES_PARAMS_RANDOM_SEARCH, BOOSTED_TREES_K_FOLD, \\\n",
    "                                   BOOSTED_TREES_RANDOMSEARCH_N_ITER, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_BT = XGBClassifier(**BOOSTED_TREES_PARAMS, **params)\n",
    "        CV_report(clf_BT, train, train_Y, BOOSTED_TREES_K_FOLD, scoring, SAMPLING)\n",
    "        \n",
    "        \n",
    "    if BOOSTED_TREES_TUNING_METHOD == 2:\n",
    "        \n",
    "        clf_BT = XGBClassifier(**BOOSTED_TREES_PARAMS)\n",
    "        params = grid_tuning(train,train_Y,clf_BT, BOOSTED_TREES_PARAMS_GRID_SEARCH, BOOSTED_TREES_K_FOLD, scoring, refit, SAMPLING)\n",
    "        \n",
    "        clf_BT = XGBClassifier(**BOOSTED_TREES_PARAMS, **params)\n",
    "        CV_report(clf_BT, train, train_Y, BOOSTED_TREES_K_FOLD, scoring, SAMPLING)\n",
    "\n",
    "    if BOOSTED_TREES_SAVE_PARAMS_TO_DISK:\n",
    "        params = clf_BT.get_params()\n",
    "        save_string = output_filepath + '/' + FOLDER_NAME + '/BOOSTED_TREES_' + BOOSTED_TREES_FILE_NAME + '.txt'\n",
    "        overwrite_protection(save_string)\n",
    "        print(\"\\nSaving hyperparameters to disk\")\n",
    "        with open(save_string, 'w') as f:\n",
    "            json.dump(params, f)\n",
    "\n",
    "    if BOOSTED_TREES_SHOW_FEATURE_IMPORTANCE:\n",
    "        print(\"Plot of feature importance:\")\n",
    "        xgb.plot_importance(clf_BT.fit(train,train_Y), max_num_features = BOOSTED_TREES_MAX_NUMBER_OF_FEATURES_TO_SHOW)\n",
    "        pyplot.show()  \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define flags and options for getting the final results from tuned models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "    Flags and Parameters for final results\n",
    "'''\n",
    "# 0 = No, 1 = Yes\n",
    "ENABLE_FINAL_RESULTS = 0\n",
    "\n",
    "if ENABLE_FINAL_RESULTS:\n",
    "    \n",
    "    #Number of folds used for CV results\n",
    "    FINAL_RESULTS_K_FOLDS = 10\n",
    "    \n",
    "    \n",
    "    #The metrics that will be reported on\n",
    "    #These are the metrics we have used before, additional metrics are easily implemented if sklearn has it implemented\n",
    "    '''\n",
    "    'accuracy': met.make_scorer(met.accuracy_score),\n",
    "    'precision': met.make_scorer(met.precision_score),\n",
    "    'sensitivity': met.make_scorer(met.recall_score),\n",
    "    'specificity': met.make_scorer(met.recall_score,pos_label = 0),\n",
    "    'f1': met.make_scorer(met.f1_score),\n",
    "    'roc_auc': met.make_scorer(met.roc_auc_score),\n",
    "    \"MCC\" : met.make_scorer(met.matthews_corrcoef)\n",
    "    '''\n",
    "    \n",
    "    FINAL_RESULTS_METRICS = {\n",
    "        'accuracy': met.make_scorer(met.accuracy_score),\n",
    "        'precision': met.make_scorer(met.precision_score),\n",
    "        'sensitivity': met.make_scorer(met.recall_score),\n",
    "        'specificity': met.make_scorer(met.recall_score,pos_label = 0),\n",
    "        'f1': met.make_scorer(met.f1_score),\n",
    "        'roc_auc': met.make_scorer(met.roc_auc_score),\n",
    "        \"MCC\" : met.make_scorer(met.matthews_corrcoef)\n",
    "    }\n",
    "                            \n",
    "    \n",
    "    # 0 = No, 1 = Yes\n",
    "    REPORT_CV_TRAIN_MEAN = 1\n",
    "    REPORT_CV_TRAIN_STD = 1\n",
    "\n",
    "    # 0 = No, 1 = Yes\n",
    "    REPORT_CV_TEST_MEAN = 1\n",
    "    REPORT_CV_TEST_STD = 1\n",
    "\n",
    "    # For actual train and test data, not CV\n",
    "    # 0 = No, 1 = Yes\n",
    "    REPORT_TRAIN = 1\n",
    "    REPORT_TEST = 1\n",
    "\n",
    "    \n",
    "    \n",
    "    # 0 = No, 1 = Yes\n",
    "    FINAL_RESULTS_LOGISTIC_REGRESSION = 1\n",
    "    if FINAL_RESULTS_LOGISTIC_REGRESSION:\n",
    "        #text file with the params you want to use in the final results\n",
    "        LOGISTIC_REGRESSION_PARAMS = \"bestparams.txt\" \n",
    "       \n",
    "    # 0 = No, 1 = Yes\n",
    "    FINAL_RESULTS_SVM = 1\n",
    "    if FINAL_RESULTS_SVM:\n",
    "        #text file with the params you want to use in the final results\n",
    "        SVM_PARAMS = \"bestparams.txt\"\n",
    "        \n",
    "    # 0 = No, 1 = Yes\n",
    "    FINAL_RESULTS_DECISION_TREE = 1\n",
    "    if FINAL_RESULTS_DECISION_TREE:\n",
    "        #text file with the params you want to use in the final results\n",
    "        DECISION_TREE_PARAMS = \"bestparams.txt\"\n",
    "           \n",
    "    # 0 = No, 1 = Yes\n",
    "    FINAL_RESULTS_RANDOM_FOREST = 1\n",
    "    if FINAL_RESULTS_RANDOM_FOREST:\n",
    "        #text file with the params you want to use in the final results\n",
    "        RANDOM_FOREST_PARAMS = \"bestparams.txt\"\n",
    "        \n",
    "    # 0 = No, 1 = Yes\n",
    "    FINAL_RESULTS_BOOSTED_TREES = 1\n",
    "    if FINAL_RESULTS_BOOSTED_TREES:\n",
    "        #text file with the params you want to use in the final results\n",
    "        DECISION_TREE_PARAMS = \"bestparams.txt\"\n",
    "     \n",
    "    # 0 = No, 1 = Yes\n",
    "    #Will be saved as a csv file with the name specified in the currently used folder \n",
    "    SAVE_FINAL_RESULTS = 1\n",
    "        \n",
    "    if SAVE_FINAL_RESULTS:\n",
    "        \n",
    "        FINAL_RESULTS_FILE_NAME = \"final_results\"\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.3s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.2s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=4)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.7s finished\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Result_Type</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>sensitivity</th>\n",
       "      <th>specificity</th>\n",
       "      <th>f1</th>\n",
       "      <th>roc_auc</th>\n",
       "      <th>MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LOGISTIC_REGRESSION_CV_TRAIN_MEAN</td>\n",
       "      <td>0.888510</td>\n",
       "      <td>0.749039</td>\n",
       "      <td>0.779544</td>\n",
       "      <td>0.920986</td>\n",
       "      <td>0.763315</td>\n",
       "      <td>0.850265</td>\n",
       "      <td>0.691258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LOGISTIC_REGRESSION_CV_TRAIN_STD</td>\n",
       "      <td>0.015320</td>\n",
       "      <td>0.044059</td>\n",
       "      <td>0.017056</td>\n",
       "      <td>0.018606</td>\n",
       "      <td>0.025479</td>\n",
       "      <td>0.013045</td>\n",
       "      <td>0.035425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LOGISTIC_REGRESSION_CV_TEST_MEAN</td>\n",
       "      <td>0.696798</td>\n",
       "      <td>0.336071</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.799134</td>\n",
       "      <td>0.335133</td>\n",
       "      <td>0.582900</td>\n",
       "      <td>0.153865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LOGISTIC_REGRESSION_CV_TEST_STD</td>\n",
       "      <td>0.063965</td>\n",
       "      <td>0.147586</td>\n",
       "      <td>0.205149</td>\n",
       "      <td>0.075645</td>\n",
       "      <td>0.161147</td>\n",
       "      <td>0.096789</td>\n",
       "      <td>0.187253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LOGISTIC_REGRESSION_TRAIN</td>\n",
       "      <td>0.865724</td>\n",
       "      <td>0.684932</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.894495</td>\n",
       "      <td>0.724638</td>\n",
       "      <td>0.831863</td>\n",
       "      <td>0.638121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LOGISTIC_REGRESSION_TEST</td>\n",
       "      <td>0.726027</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.668687</td>\n",
       "      <td>0.316907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVM_CV_TRAIN_MEAN</td>\n",
       "      <td>0.950920</td>\n",
       "      <td>0.862461</td>\n",
       "      <td>0.938515</td>\n",
       "      <td>0.954633</td>\n",
       "      <td>0.898100</td>\n",
       "      <td>0.946574</td>\n",
       "      <td>0.867923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>SVM_CV_TRAIN_STD</td>\n",
       "      <td>0.010005</td>\n",
       "      <td>0.035630</td>\n",
       "      <td>0.024346</td>\n",
       "      <td>0.015225</td>\n",
       "      <td>0.018090</td>\n",
       "      <td>0.010435</td>\n",
       "      <td>0.022793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SVM_CV_TEST_MEAN</td>\n",
       "      <td>0.741872</td>\n",
       "      <td>0.485335</td>\n",
       "      <td>0.464286</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.453521</td>\n",
       "      <td>0.645022</td>\n",
       "      <td>0.302374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVM_CV_TEST_STD</td>\n",
       "      <td>0.067998</td>\n",
       "      <td>0.213612</td>\n",
       "      <td>0.132673</td>\n",
       "      <td>0.090331</td>\n",
       "      <td>0.121603</td>\n",
       "      <td>0.066707</td>\n",
       "      <td>0.171552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVM_TRAIN</td>\n",
       "      <td>0.869258</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.753846</td>\n",
       "      <td>0.903670</td>\n",
       "      <td>0.725926</td>\n",
       "      <td>0.828758</td>\n",
       "      <td>0.640992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVM_TEST</td>\n",
       "      <td>0.712329</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.781818</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.640909</td>\n",
       "      <td>0.268334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DECISION_TREE_CV_TRAIN_MEAN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DECISION_TREE_CV_TRAIN_STD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>DECISION_TREE_CV_TEST_MEAN</td>\n",
       "      <td>0.698645</td>\n",
       "      <td>0.408672</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.779437</td>\n",
       "      <td>0.399537</td>\n",
       "      <td>0.604004</td>\n",
       "      <td>0.215943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>DECISION_TREE_CV_TEST_STD</td>\n",
       "      <td>0.090875</td>\n",
       "      <td>0.220447</td>\n",
       "      <td>0.144828</td>\n",
       "      <td>0.117209</td>\n",
       "      <td>0.145944</td>\n",
       "      <td>0.089085</td>\n",
       "      <td>0.204168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>DECISION_TREE_TRAIN</td>\n",
       "      <td>0.869258</td>\n",
       "      <td>0.679487</td>\n",
       "      <td>0.815385</td>\n",
       "      <td>0.885321</td>\n",
       "      <td>0.741259</td>\n",
       "      <td>0.850353</td>\n",
       "      <td>0.659624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>DECISION_TREE_TEST</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.836364</td>\n",
       "      <td>0.540541</td>\n",
       "      <td>0.695960</td>\n",
       "      <td>0.384982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RANDOM_FOREST_CV_TRAIN_MEAN</td>\n",
       "      <td>0.773474</td>\n",
       "      <td>0.506789</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.705871</td>\n",
       "      <td>0.671733</td>\n",
       "      <td>0.852936</td>\n",
       "      <td>0.598092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>RANDOM_FOREST_CV_TRAIN_STD</td>\n",
       "      <td>0.037138</td>\n",
       "      <td>0.040139</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.048583</td>\n",
       "      <td>0.035328</td>\n",
       "      <td>0.024291</td>\n",
       "      <td>0.044202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>RANDOM_FOREST_CV_TEST_MEAN</td>\n",
       "      <td>0.567365</td>\n",
       "      <td>0.321804</td>\n",
       "      <td>0.685714</td>\n",
       "      <td>0.536364</td>\n",
       "      <td>0.425541</td>\n",
       "      <td>0.611039</td>\n",
       "      <td>0.196875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>RANDOM_FOREST_CV_TEST_STD</td>\n",
       "      <td>0.119661</td>\n",
       "      <td>0.082062</td>\n",
       "      <td>0.157863</td>\n",
       "      <td>0.173770</td>\n",
       "      <td>0.075158</td>\n",
       "      <td>0.079650</td>\n",
       "      <td>0.140905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>RANDOM_FOREST_TRAIN</td>\n",
       "      <td>0.872792</td>\n",
       "      <td>0.698630</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.739130</td>\n",
       "      <td>0.841849</td>\n",
       "      <td>0.657322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>RANDOM_FOREST_TEST</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.473684</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.486486</td>\n",
       "      <td>0.659091</td>\n",
       "      <td>0.312550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BOOSTED_TREES_CV_TRAIN_MEAN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BOOSTED_TREES_CV_TRAIN_STD</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BOOSTED_TREES_CV_TEST_MEAN</td>\n",
       "      <td>0.759360</td>\n",
       "      <td>0.513904</td>\n",
       "      <td>0.495238</td>\n",
       "      <td>0.839394</td>\n",
       "      <td>0.480070</td>\n",
       "      <td>0.667316</td>\n",
       "      <td>0.344594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BOOSTED_TREES_CV_TEST_STD</td>\n",
       "      <td>0.062421</td>\n",
       "      <td>0.115939</td>\n",
       "      <td>0.152008</td>\n",
       "      <td>0.100199</td>\n",
       "      <td>0.088402</td>\n",
       "      <td>0.057821</td>\n",
       "      <td>0.104973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BOOSTED_TREES_TRAIN</td>\n",
       "      <td>0.869258</td>\n",
       "      <td>0.694444</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.899083</td>\n",
       "      <td>0.729927</td>\n",
       "      <td>0.834157</td>\n",
       "      <td>0.645443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BOOSTED_TREES_TEST</td>\n",
       "      <td>0.753425</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.686869</td>\n",
       "      <td>0.361186</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Result_Type  accuracy  precision  sensitivity  \\\n",
       "0   LOGISTIC_REGRESSION_CV_TRAIN_MEAN  0.888510   0.749039     0.779544   \n",
       "1    LOGISTIC_REGRESSION_CV_TRAIN_STD  0.015320   0.044059     0.017056   \n",
       "2    LOGISTIC_REGRESSION_CV_TEST_MEAN  0.696798   0.336071     0.366667   \n",
       "3     LOGISTIC_REGRESSION_CV_TEST_STD  0.063965   0.147586     0.205149   \n",
       "4           LOGISTIC_REGRESSION_TRAIN  0.865724   0.684932     0.769231   \n",
       "5            LOGISTIC_REGRESSION_TEST  0.726027   0.454545     0.555556   \n",
       "6                   SVM_CV_TRAIN_MEAN  0.950920   0.862461     0.938515   \n",
       "7                    SVM_CV_TRAIN_STD  0.010005   0.035630     0.024346   \n",
       "8                    SVM_CV_TEST_MEAN  0.741872   0.485335     0.464286   \n",
       "9                     SVM_CV_TEST_STD  0.067998   0.213612     0.132673   \n",
       "10                          SVM_TRAIN  0.869258   0.700000     0.753846   \n",
       "11                           SVM_TEST  0.712329   0.428571     0.500000   \n",
       "12        DECISION_TREE_CV_TRAIN_MEAN  1.000000   1.000000     1.000000   \n",
       "13         DECISION_TREE_CV_TRAIN_STD  0.000000   0.000000     0.000000   \n",
       "14         DECISION_TREE_CV_TEST_MEAN  0.698645   0.408672     0.428571   \n",
       "15          DECISION_TREE_CV_TEST_STD  0.090875   0.220447     0.144828   \n",
       "16                DECISION_TREE_TRAIN  0.869258   0.679487     0.815385   \n",
       "17                 DECISION_TREE_TEST  0.767123   0.526316     0.555556   \n",
       "18        RANDOM_FOREST_CV_TRAIN_MEAN  0.773474   0.506789     1.000000   \n",
       "19         RANDOM_FOREST_CV_TRAIN_STD  0.037138   0.040139     0.000000   \n",
       "20         RANDOM_FOREST_CV_TEST_MEAN  0.567365   0.321804     0.685714   \n",
       "21          RANDOM_FOREST_CV_TEST_STD  0.119661   0.082062     0.157863   \n",
       "22                RANDOM_FOREST_TRAIN  0.872792   0.698630     0.784615   \n",
       "23                 RANDOM_FOREST_TEST  0.739726   0.473684     0.500000   \n",
       "24        BOOSTED_TREES_CV_TRAIN_MEAN  1.000000   1.000000     1.000000   \n",
       "25         BOOSTED_TREES_CV_TRAIN_STD  0.000000   0.000000     0.000000   \n",
       "26         BOOSTED_TREES_CV_TEST_MEAN  0.759360   0.513904     0.495238   \n",
       "27          BOOSTED_TREES_CV_TEST_STD  0.062421   0.115939     0.152008   \n",
       "28                BOOSTED_TREES_TRAIN  0.869258   0.694444     0.769231   \n",
       "29                 BOOSTED_TREES_TEST  0.753425   0.500000     0.555556   \n",
       "\n",
       "    specificity        f1   roc_auc       MCC  \n",
       "0      0.920986  0.763315  0.850265  0.691258  \n",
       "1      0.018606  0.025479  0.013045  0.035425  \n",
       "2      0.799134  0.335133  0.582900  0.153865  \n",
       "3      0.075645  0.161147  0.096789  0.187253  \n",
       "4      0.894495  0.724638  0.831863  0.638121  \n",
       "5      0.781818  0.500000  0.668687  0.316907  \n",
       "6      0.954633  0.898100  0.946574  0.867923  \n",
       "7      0.015225  0.018090  0.010435  0.022793  \n",
       "8      0.825758  0.453521  0.645022  0.302374  \n",
       "9      0.090331  0.121603  0.066707  0.171552  \n",
       "10     0.903670  0.725926  0.828758  0.640992  \n",
       "11     0.781818  0.461538  0.640909  0.268334  \n",
       "12     1.000000  1.000000  1.000000  1.000000  \n",
       "13     0.000000  0.000000  0.000000  0.000000  \n",
       "14     0.779437  0.399537  0.604004  0.215943  \n",
       "15     0.117209  0.145944  0.089085  0.204168  \n",
       "16     0.885321  0.741259  0.850353  0.659624  \n",
       "17     0.836364  0.540541  0.695960  0.384982  \n",
       "18     0.705871  0.671733  0.852936  0.598092  \n",
       "19     0.048583  0.035328  0.024291  0.044202  \n",
       "20     0.536364  0.425541  0.611039  0.196875  \n",
       "21     0.173770  0.075158  0.079650  0.140905  \n",
       "22     0.899083  0.739130  0.841849  0.657322  \n",
       "23     0.818182  0.486486  0.659091  0.312550  \n",
       "24     1.000000  1.000000  1.000000  1.000000  \n",
       "25     0.000000  0.000000  0.000000  0.000000  \n",
       "26     0.839394  0.480070  0.667316  0.344594  \n",
       "27     0.100199  0.088402  0.057821  0.104973  \n",
       "28     0.899083  0.729927  0.834157  0.645443  \n",
       "29     0.818182  0.526316  0.686869  0.361186  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File already exists, are you sure you want to overwrite  final_results.csv  in the folder  C:/Users/Briggstone/Documents/Master 2020/Processed data/example ?\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Y?: Y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saving results to disk\n"
     ]
    }
   ],
   "source": [
    "def cv_report_helper_function (rows_list, model_string, cv_report):\n",
    "\n",
    "    if REPORT_CV_TRAIN_MEAN:\n",
    "        results = { \"Result_Type\" : model_string + \"CV_TRAIN_MEAN\"}\n",
    "        for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "            results[k] = cv_report.loc[cv_report[\"Metric\"] == k, \"Train mean\"].values[0]\n",
    "            \n",
    "        rows_list.append(results)\n",
    "        \n",
    "    if REPORT_CV_TRAIN_STD:\n",
    "        results = { \"Result_Type\" : model_string + \"CV_TRAIN_STD\"}\n",
    "        for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "            results[k] = cv_report.loc[cv_report[\"Metric\"] == k, \"Train SD\"].values[0]\n",
    "\n",
    "        rows_list.append(results)\n",
    "        \n",
    "        \n",
    "    if REPORT_CV_TEST_MEAN:\n",
    "        results = { \"Result_Type\" : model_string + \"CV_TEST_MEAN\"}\n",
    "        for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "            results[k] = cv_report.loc[cv_report[\"Metric\"] == k, \"Test mean\"].values[0]\n",
    "\n",
    "        rows_list.append(results)\n",
    "        \n",
    "    if REPORT_CV_TEST_STD:\n",
    "        results = { \"Result_Type\" : model_string + \"CV_TEST_STD\"}\n",
    "        for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "            results[k] = cv_report.loc[cv_report[\"Metric\"] == k, \"Test SD\"].values[0]\n",
    "\n",
    "        rows_list.append(results)\n",
    "        \n",
    "        \n",
    "def scorer_helper_function(y_true,y_pred,scorer_string):\n",
    "    \n",
    "    if scorer_string == \"accuracy\":\n",
    "        return met.accuracy_score(y_true, y_pred)\n",
    "    elif scorer_string == \"precision\":\n",
    "        return met.precision_score(y_true,y_pred)\n",
    "    elif scorer_string == \"sensitivity\":\n",
    "        return met.recall_score(y_true,y_pred)\n",
    "    elif scorer_string == \"specificity\":\n",
    "        return met.recall_score(y_true,y_pred, pos_label = 0)\n",
    "    elif scorer_string == \"f1\":\n",
    "        return met.f1_score(y_true,y_pred)\n",
    "    elif scorer_string == \"roc_auc\":\n",
    "        return met.roc_auc_score(y_true,y_pred)\n",
    "    elif scorer_string == \"MCC\":\n",
    "        return met.matthews_corrcoef(y_true,y_pred)\n",
    "        \n",
    "        \n",
    "def results_helper_function(rows_list, model_string, model):\n",
    "    \n",
    "    if SAMPLING != \"NONE\":\n",
    "        if SAMPLING == \"SMOTE\":\n",
    "            model = over_sampling(model,train)\n",
    "     \n",
    "    fit = model.fit(train,train_Y)\n",
    "    if REPORT_TRAIN:\n",
    "        results_train = fit.predict(train)\n",
    "        \n",
    "        results = { \"Result_Type\" : model_string + \"TRAIN\"}\n",
    "        \n",
    "        for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "            results[k] = scorer_helper_function(train_Y,results_train,k)\n",
    "            \n",
    "        rows_list.append(results)\n",
    "        \n",
    "    if REPORT_TEST:\n",
    "        results_test = fit.predict(test)\n",
    "               \n",
    "        results = { \"Result_Type\" : model_string + \"TEST\"}\n",
    "        \n",
    "        for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "            results[k] = scorer_helper_function(test_Y, results_test, k)\n",
    "            \n",
    "        rows_list.append(results)\n",
    "        \n",
    "    \n",
    "\n",
    "if ENABLE_FINAL_RESULTS:\n",
    "    \n",
    "    columns = [\"Result_Type\"]\n",
    "    for k,_ in FINAL_RESULTS_METRICS.items():\n",
    "        columns.append(k)\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(columns = columns)\n",
    "    rows_list = []\n",
    "    \n",
    "    if FINAL_RESULTS_LOGISTIC_REGRESSION:\n",
    "        filepath = output_filepath + '/' + FOLDER_NAME + '/LOGISTIC_REGRESSION_' + LOGISTIC_REGRESSION_PARAMS\n",
    "        with open(filepath,'r') as f:\n",
    "            params = json.load(f)\n",
    "        \n",
    "        clf_log = LogisticRegression(**params)\n",
    "        \n",
    "        if REPORT_CV_TRAIN_MEAN or REPORT_CV_TRAIN_STD or REPORT_CV_TEST_MEAN or REPORT_CV_TEST_STD:\n",
    "            \n",
    "            results = CV_report(clf_log, train, train_Y, FINAL_RESULTS_K_FOLDS, FINAL_RESULTS_METRICS, SAMPLING, return_results = True)\n",
    "            cv_report_helper_function(rows_list, \"LOGISTIC_REGRESSION_\", results)\n",
    "            results_helper_function(rows_list, \"LOGISTIC_REGRESSION_\", clf_log)\n",
    "        \n",
    "    if FINAL_RESULTS_SVM:\n",
    "        filepath = output_filepath + '/' + FOLDER_NAME + '/SVM_' + SVM_PARAMS\n",
    "        with open(filepath,'r') as f:\n",
    "            params = json.load(f)\n",
    "        \n",
    "        clf_svm = svm.SVC(**params)\n",
    "        \n",
    "        if REPORT_CV_TRAIN_MEAN or REPORT_CV_TRAIN_STD or REPORT_CV_TEST_MEAN or REPORT_CV_TEST_STD:\n",
    "            \n",
    "            results = CV_report(clf_svm, train, train_Y, FINAL_RESULTS_K_FOLDS, FINAL_RESULTS_METRICS, SAMPLING, return_results = True)\n",
    "            cv_report_helper_function(rows_list, \"SVM_\", results)\n",
    "            results_helper_function(rows_list, \"SVM_\", clf_log)   \n",
    "            \n",
    "     \n",
    "    if FINAL_RESULTS_DECISION_TREE:\n",
    "        filepath = output_filepath + '/' + FOLDER_NAME + '/DECISION_TREE_' + DECISION_TREE_PARAMS\n",
    "        with open(filepath,'r') as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        clf_DT = DecisionTreeClassifier(**params)\n",
    "\n",
    "        if REPORT_CV_TRAIN_MEAN or REPORT_CV_TRAIN_STD or REPORT_CV_TEST_MEAN or REPORT_CV_TEST_STD:\n",
    "\n",
    "            results = CV_report(clf_DT, train, train_Y, FINAL_RESULTS_K_FOLDS, FINAL_RESULTS_METRICS, SAMPLING, return_results = True)\n",
    "            cv_report_helper_function(rows_list, \"DECISION_TREE_\", results)\n",
    "            results_helper_function(rows_list, \"DECISION_TREE_\", clf_log)   \n",
    "\n",
    "\n",
    "    if FINAL_RESULTS_RANDOM_FOREST:\n",
    "        filepath = output_filepath + '/' + FOLDER_NAME + '/RANDOM_FOREST_' + DECISION_TREE_PARAMS\n",
    "        with open(filepath,'r') as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        clf_RF = XGBClassifier(**params)\n",
    "\n",
    "        if REPORT_CV_TRAIN_MEAN or REPORT_CV_TRAIN_STD or REPORT_CV_TEST_MEAN or REPORT_CV_TEST_STD:\n",
    "\n",
    "            results = CV_report(clf_RF, train, train_Y, FINAL_RESULTS_K_FOLDS, FINAL_RESULTS_METRICS, SAMPLING, return_results = True)\n",
    "            cv_report_helper_function(rows_list, \"RANDOM_FOREST_\", results)\n",
    "            results_helper_function(rows_list, \"RANDOM_FOREST_\", clf_log)   \n",
    "    \n",
    "    \n",
    "    if FINAL_RESULTS_BOOSTED_TREES:\n",
    "        filepath = output_filepath + '/' + FOLDER_NAME + '/BOOSTED_TREES_' + DECISION_TREE_PARAMS\n",
    "        with open(filepath,'r') as f:\n",
    "            params = json.load(f)\n",
    "\n",
    "        clf_BT = XGBClassifier(**params)\n",
    "\n",
    "        if REPORT_CV_TRAIN_MEAN or REPORT_CV_TRAIN_STD or REPORT_CV_TEST_MEAN or REPORT_CV_TEST_STD:\n",
    "\n",
    "            results = CV_report(clf_BT, train, train_Y, FINAL_RESULTS_K_FOLDS, FINAL_RESULTS_METRICS, SAMPLING, return_results = True)\n",
    "            cv_report_helper_function(rows_list, \"BOOSTED_TREES_\", results)\n",
    "            results_helper_function(rows_list, \"BOOSTED_TREES_\", clf_log)      \n",
    "    \n",
    "    \n",
    "   \n",
    "    results = df.append(pd.DataFrame(rows_list), sort = False)\n",
    "                \n",
    "    display(results)        \n",
    "            \n",
    "       \n",
    "    if SAVE_FINAL_RESULTS:\n",
    "        save_string = output_filepath + '/' + FOLDER_NAME + '/' + FINAL_RESULTS_FILE_NAME + '.csv'\n",
    "        overwrite_protection(save_string)\n",
    "        print(\"\\nSaving results to disk\")\n",
    "        results.to_csv(save_string, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
