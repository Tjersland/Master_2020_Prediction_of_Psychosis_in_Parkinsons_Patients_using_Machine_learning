{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Input the directory where your database is located \n",
    "os.chdir('C:/Users/Briggstone/Documents/Master 2020/Parkinson_PPMI')\n",
    "#os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Parkinson_PPMI')\n",
    "\n",
    "#Where you want the csv file of the merged data to be placed\n",
    "output_filepath = 'C:/Users/Briggstone/Documents/Master 2020/Processed data'\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we select the subset of patients with parkinson's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total subjects in original data table:  2200\n",
      "Number of subjects with parkinson's in data table: 489\n"
     ]
    }
   ],
   "source": [
    "#Reading the data table Screening demographics into a pandas dataframe\n",
    "data = pd.read_csv('_Subject_Characteristics/Screening___Demographics.csv') \n",
    "print(\"Number of total subjects in original data table: \", data.shape[0])\n",
    "\n",
    "#Discarding indviduals that do not have confirmed parkinson's, Everyone except APPRDX == 1.\n",
    "data = data.loc[data.APPRDX == 1]\n",
    "print(\"Number of subjects with parkinson's in data table:\", data.shape[0])\n",
    "\n",
    "#Selecting only PATNO column and reseting index (0-1-2 instead of 2-6-9). Index was weird due to dropping columns in the previous lines. \n",
    "pat_subset = pd.DataFrame(data.loc[:, \"PATNO\"].reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our data tables into pandas DataFrames and select the features we want from each data table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to 1 if using event_id for longitudinal joining or 0 if using infodt\n",
    "long_flag = 1\n",
    "LED = [\"INFODT\", \"EVENT_ID\"]\n",
    "\n",
    "\n",
    "#Importing data tables from non-motor and selecting relevant columns\n",
    "MOCA = pd.read_csv(\"Non-motor_Assessments/Montreal_Cognitive_Assessment__MoCA_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"MCATOT\"]]\n",
    "\n",
    "HPLT = pd.read_csv(\"Non-motor_Assessments/Hopkins_Verbal_Learning_Test.csv\").loc[:,[\"PATNO\", LED[long_flag], \"DVT_DELAYED_RECALL\"]]\n",
    "\n",
    "BJLO = pd.read_csv(\"Non-motor_Assessments/Benton_Judgment_of_Line_Orientation.csv\").loc[:,[\"PATNO\", LED[long_flag], \"JLO_TOTRAW\"]]\n",
    "\n",
    "LNSQ = pd.read_csv(\"Non-motor_Assessments/Letter_-_Number_Sequencing__PD_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"LNS_TOTRAW\"]]\n",
    "\n",
    "SEFL = pd.read_csv(\"Non-motor_Assessments/Semantic_Fluency.csv\").loc[:,[\"PATNO\", LED[long_flag], \"VLTANIM\", \"VLTVEG\", \"VLTFRUIT\"]]\n",
    "\n",
    "REMQ = pd.read_csv(\"Non-motor_Assessments/REM_Sleep_Disorder_Questionnaire.csv\").loc[:,[\"PATNO\", LED[long_flag], \"DRMVIVID\", \"DRMAGRAC\", \\\n",
    "    \"DRMNOCTB\", \"SLPLMBMV\", \"SLPINJUR\", \"DRMVERBL\", \"DRMFIGHT\", \"DRMUMV\", \"DRMOBJFL\", \"MVAWAKEN\", \"DRMREMEM\", \"SLPDSTRB\", \"STROKE\", \\\n",
    "    \"HETRA\", \"PARKISM\", \"RLS\", \"NARCLPSY\", \"DEPRS\", \"EPILEPSY\", \"BRNINFM\", \"CNSOTH\"]]\n",
    "\n",
    "GDSS = pd.read_csv(\"Non-motor_Assessments/Geriatric_Depression_Scale__Short_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"GDSSATIS\", \"GDSDROPD\", \\\n",
    "    \"GDSEMPTY\", \"GDSBORED\", \"GDSGSPIR\", \"GDSAFRAD\", \"GDSHAPPY\", \"GDSHLPLS\", \"GDSHOME\", \"GDSMEMRY\", \"GDSALIVE\", \"GDSWRTLS\", \"GDSENRGY\", \\\n",
    "    \"GDSHOPLS\", \"GDSBETER\"]]\n",
    "\n",
    "SIDT = pd.read_csv(\"Non-motor_Assessments/University_of_Pennsylvania_Smell_ID_Test.csv\").loc[:,[\"PATNO\", \"UPSITBK1\", \"UPSITBK2\", \\\n",
    "    \"UPSITBK3\", \"UPSITBK4\"]]\n",
    "\n",
    "EPSS = pd.read_csv(\"Non-motor_Assessments/Epworth_Sleepiness_Scale.csv\").loc[:,[\"PATNO\", LED[long_flag], \"ESS1\", \"ESS2\", \\\n",
    "    \"ESS3\", \"ESS4\", \"ESS5\", \"ESS6\", \"ESS7\", \"ESS8\"]]\n",
    "\n",
    "SCOP = pd.read_csv(\"Non-motor_Assessments/SCOPA-AUT.csv\").loc[:,[\"PATNO\", LED[long_flag], \"SCAU1\", \"SCAU2\", \\\n",
    "    \"SCAU3\", \"SCAU4\", \"SCAU5\", \"SCAU6\", \"SCAU7\", \"SCAU8\", \"SCAU9\", \"SCAU10\", \"SCAU11\", \"SCAU12\", \"SCAU13\", \\\n",
    "    \"SCAU14\", \"SCAU15\", \"SCAU16\", \"SCAU17\", \"SCAU18\", \"SCAU19\", \"SCAU20\", \"SCAU21\", \"SCAU22\", \"SCAU23\", \"SCAU24\", \"SCAU25\"]]\n",
    "\n",
    "\n",
    "\n",
    "#Importing data tables from motor\n",
    "MSU3 = pd.read_csv(\"Motor___MDS-UPDRS/MDS_UPDRS_Part_III.csv\").loc[:,[\"PATNO\", LED[long_flag], 'NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR', 'PAG_NAME', 'PD_MED_USE']]\n",
    "MSU1 = pd.read_csv(\"Motor___MDS-UPDRS/MDS_UPDRS_Part_I.csv\").loc[:,[\"PATNO\", LED[long_flag], \"NP1HALL\", \"NP1COG\"]]\n",
    "MSU2 = pd.read_csv (\"Motor___MDS-UPDRS/MDS_UPDRS_Part_II__Patient_Questionnaire.csv\").loc[:,[\"PATNO\", LED[long_flag], \"NP2TRMR\", \"NP2WALK\", \"NP2FREZ\"]]\n",
    "\n",
    "#Importing data tables from subject characteristics\n",
    "FMHS = pd.read_csv(\"_Subject_Characteristics/Family_History__PD_.csv\").loc[:,[\"PATNO\", \"BIOMOMPD\", \"BIODADPD\", \\\n",
    "    \"FULSIBPD\", \"HAFSIBPD\", \"MAGPARPD\", \"PAGPARPD\", \"MATAUPD\", \"PATAUPD\", \"KIDSPD\"]]\n",
    "SOEC = pd.read_csv(\"_Subject_Characteristics/Socio-Economics.csv\").loc[:,[\"PATNO\", \"EDUCYRS\"]]\n",
    "SCDE = pd.read_csv(\"_Subject_Characteristics/Screening___Demographics.csv\").loc[:,[\"PATNO\", \"PRJENRDT\", \"BIRTHDT\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do any additional preprocessing on the data before we perform our data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC to BL for MOCA as it has no Baseline data\n",
    "MOCA.loc[MOCA[\"EVENT_ID\"] == \"SC\", \"EVENT_ID\"] = \"BL\"\n",
    "\n",
    "#Drop MSU3 data entries that are post drug-administering\n",
    "\n",
    "MSU3 = MSU3.drop(MSU3[ MSU3['PAG_NAME'] == \"NUPDRS3A\" ].index)\n",
    "MSU3 = MSU3.drop(\"PAG_NAME\", axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we perform our data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of join: Merge non-longitudinal data\n",
    "pat_subset = pd.DataFrame(pat_subset)\n",
    "data = pat_subset.merge(FMHS, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SOEC, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SCDE, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SIDT, how = \"inner\", on = \"PATNO\")\n",
    "\n",
    "\n",
    "#Second step of join: Merge in longitudinal data\n",
    "\n",
    "#This data table has duplicate entries for the same data, test is done before drug is administered and after\n",
    "data = data.merge(MSU3, how = \"inner\", on =\"PATNO\")\n",
    "\n",
    "data = data.merge(MSU1, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(MOCA, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(HPLT, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(BJLO, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(LNSQ, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(SEFL, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(GDSS, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(EPSS, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(SCOP, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(REMQ, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(MSU2, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do some additional processing post merge and output the merged data table to a csv file so that it can be further processed in missingvalues.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing birthdate and project enrollment date and adding age as a function of these two columns\n",
    "\n",
    "tempdata = data.loc[:, [\"PRJENRDT\", \"BIRTHDT\"]]\n",
    "tempdata.PRJENRDT = tempdata.apply(lambda row_wise: int(row_wise[\"PRJENRDT\"][-4:]), axis = 1)\n",
    "tempdata.BIRTHDT = tempdata.apply(lambda row_wise: int(row_wise[\"BIRTHDT\"]), axis = 1)\n",
    "data [\"AGE_BL\"] = tempdata.PRJENRDT - tempdata.BIRTHDT\n",
    "data = data.drop([\"PRJENRDT\", \"BIRTHDT\"], axis = 1)\n",
    "\n",
    "data.to_csv(output_filepath + '/joined_data.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell we can do any final data inspection (Number of unique patients, shape, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (2341, 130)\n",
      "Number of unique PATNO: 425\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Inspecting the merged data\n",
    "\n",
    "#np.sort(data.columns.values)\n",
    "print( \"Data shape\", data.shape)\n",
    "print( \"Number of unique PATNO:\", data.PATNO.unique().size)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
