{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO \n",
    "\n",
    "SEE IF WE CAN SAMPLE FROM GENETIC COHORT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Input the directory where your database is located \n",
    "#os.chdir('C:/Users/Briggstone/Documents/Master 2020/Parkinson_PPMI')\n",
    "os.chdir('C:/Users/Trond/Documents/Master 2020/Parkinson_PPMI')\n",
    "#os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Parkinson_PPMI')\n",
    "\n",
    "#Where you want the csv file of the merged data to be placed\n",
    "output_filepath = 'C:/Users/Briggstone/Documents/Master 2020/Processed data'\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we select the subset of patients with parkinson's that have valid enrollment dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of total subjects in original data table:  2200\n",
      "Number of subjects with parkinson's in data table: 260\n"
     ]
    }
   ],
   "source": [
    "#Reading the data table Screening demographics into a pandas dataframe\n",
    "data = pd.read_csv('_Subject_Characteristics/Screening___Demographics.csv') \n",
    "print(\"Number of total subjects in original data table: \", data.shape[0])\n",
    "data2 = pd.read_csv('Study_Enrollment/Randomization_table.csv')\n",
    "data = data.merge(data2, how = \"inner\", on = \"PATNO\")\n",
    "\n",
    "#Discarding indviduals that do not have confirmed parkinson's, Everyone except APPRDX == 1. Also making sure that the subject has a valid enrollment date in the project\n",
    "data = data.loc[(data.APPRDX == 5) & (data.ENROLLDT.notna())]\n",
    "print(\"Number of subjects with parkinson's in data table:\", data.shape[0])\n",
    "\n",
    "\n",
    "#Selecting only PATNO and ENROLLDT columns and reseting index (0-1-2 instead of 2-6-9). Index was weird due to dropping columns in the previous lines. \n",
    "pat_subset = pd.DataFrame(data.loc[:, [\"PATNO\", \"ENROLLDT\"]].reset_index(drop = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our data tables into pandas DataFrames and select the features we want from each data table. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set this flag to 1 if using event_id for longitudinal joining or 0 if using infodt\n",
    "long_flag = 1\n",
    "LED = [\"INFODT\", \"EVENT_ID\"]\n",
    "\n",
    "\n",
    "#Importing data tables from non-motor and selecting relevant columns\n",
    "MOCA = pd.read_csv(\"Non-motor_Assessments/Montreal_Cognitive_Assessment__MoCA_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"MCATOT\"]]\n",
    "\n",
    "HPLT = pd.read_csv(\"Non-motor_Assessments/Hopkins_Verbal_Learning_Test.csv\").loc[:,[\"PATNO\", LED[long_flag], \"DVT_DELAYED_RECALL\"]]\n",
    "\n",
    "BJLO = pd.read_csv(\"Non-motor_Assessments/Benton_Judgment_of_Line_Orientation.csv\").loc[:,[\"PATNO\", LED[long_flag], \"JLO_TOTRAW\"]]\n",
    "\n",
    "LNSQ = pd.read_csv(\"Non-motor_Assessments/Letter_-_Number_Sequencing__PD_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"LNS_TOTRAW\"]]\n",
    "\n",
    "SEFL = pd.read_csv(\"Non-motor_Assessments/Semantic_Fluency.csv\").loc[:,[\"PATNO\", LED[long_flag], \"VLTANIM\", \"VLTVEG\", \"VLTFRUIT\"]]\n",
    "\n",
    "REMQ = pd.read_csv(\"Non-motor_Assessments/REM_Sleep_Disorder_Questionnaire.csv\").loc[:,[\"PATNO\", LED[long_flag], \"DRMVIVID\", \"DRMAGRAC\", \\\n",
    "    \"DRMNOCTB\", \"SLPLMBMV\", \"SLPINJUR\", \"DRMVERBL\", \"DRMFIGHT\", \"DRMUMV\", \"DRMOBJFL\", \"MVAWAKEN\", \"DRMREMEM\", \"SLPDSTRB\", \"STROKE\", \\\n",
    "    \"HETRA\", \"PARKISM\", \"RLS\", \"NARCLPSY\", \"DEPRS\", \"EPILEPSY\", \"BRNINFM\", \"CNSOTH\"]]\n",
    "\n",
    "GDSS = pd.read_csv(\"Non-motor_Assessments/Geriatric_Depression_Scale__Short_.csv\").loc[:,[\"PATNO\", LED[long_flag], \"GDSSATIS\", \"GDSDROPD\", \\\n",
    "    \"GDSEMPTY\", \"GDSBORED\", \"GDSGSPIR\", \"GDSAFRAD\", \"GDSHAPPY\", \"GDSHLPLS\", \"GDSHOME\", \"GDSMEMRY\", \"GDSALIVE\", \"GDSWRTLS\", \"GDSENRGY\", \\\n",
    "    \"GDSHOPLS\", \"GDSBETER\"]]\n",
    "\n",
    "SIDT = pd.read_csv(\"Non-motor_Assessments/University_of_Pennsylvania_Smell_ID_Test.csv\").loc[:,[\"PATNO\", \"UPSITBK1\", \"UPSITBK2\", \\\n",
    "    \"UPSITBK3\", \"UPSITBK4\"]]\n",
    "\n",
    "EPSS = pd.read_csv(\"Non-motor_Assessments/Epworth_Sleepiness_Scale.csv\").loc[:,[\"PATNO\", LED[long_flag], \"ESS1\", \"ESS2\", \\\n",
    "    \"ESS3\", \"ESS4\", \"ESS5\", \"ESS6\", \"ESS7\", \"ESS8\"]]\n",
    "\n",
    "SCOP = pd.read_csv(\"Non-motor_Assessments/SCOPA-AUT.csv\").loc[:,[\"PATNO\", LED[long_flag], \"SCAU1\", \"SCAU2\", \\\n",
    "    \"SCAU3\", \"SCAU4\", \"SCAU5\", \"SCAU6\", \"SCAU7\", \"SCAU8\", \"SCAU9\", \"SCAU10\", \"SCAU11\", \"SCAU12\", \"SCAU13\", \\\n",
    "    \"SCAU14\", \"SCAU15\", \"SCAU16\", \"SCAU17\", \"SCAU18\", \"SCAU19\", \"SCAU20\", \"SCAU21\", \"SCAU22\", \"SCAU23\", \"SCAU24\", \"SCAU25\"]]\n",
    "\n",
    "\n",
    "\n",
    "#Importing data tables from motor\n",
    "MSU3 = pd.read_csv(\"Motor___MDS-UPDRS/MDS_UPDRS_Part_III.csv\").loc[:,[\"PATNO\", LED[long_flag], 'NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR', 'PAG_NAME', 'PD_MED_USE', 'NHY']]\n",
    "MSU1 = pd.read_csv(\"Motor___MDS-UPDRS/MDS_UPDRS_Part_I.csv\").loc[:,[\"PATNO\", LED[long_flag], \"NP1HALL\", \"NP1COG\"]]\n",
    "MSU2 = pd.read_csv (\"Motor___MDS-UPDRS/MDS_UPDRS_Part_II__Patient_Questionnaire.csv\").loc[:,[\"PATNO\", LED[long_flag], \"NP2TRMR\", \"NP2WALK\", \"NP2FREZ\"]]\n",
    "\n",
    "#Importing data tables from subject characteristics\n",
    "FMHS = pd.read_csv(\"_Subject_Characteristics/Family_History__PD_.csv\").loc[:,[\"PATNO\", \"BIOMOMPD\", \"BIODADPD\", \\\n",
    "    \"FULSIBPD\", \"HAFSIBPD\", \"MAGPARPD\", \"PAGPARPD\", \"MATAUPD\", \"PATAUPD\", \"KIDSPD\"]]\n",
    "SOEC = pd.read_csv(\"_Subject_Characteristics/Socio-Economics.csv\").loc[:,[\"PATNO\", \"EDUCYRS\"]]\n",
    "SCDE = pd.read_csv(\"_Subject_Characteristics/Screening___Demographics.csv\").loc[:,[\"PATNO\", \"BIRTHDT\", \"GENDER\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do any additional preprocessing on the data before we perform our data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SC to BL for MOCA as it has no Baseline data\n",
    "MOCA.loc[MOCA[\"EVENT_ID\"] == \"SC\", \"EVENT_ID\"] = \"BL\"\n",
    "\n",
    "#Drop MSU3 data entries that are post drug-administering\n",
    "\n",
    "MSU3 = MSU3.drop(MSU3[ MSU3['PAG_NAME'] == \"NUPDRS3A\" ].index)\n",
    "MSU3 = MSU3.drop(\"PAG_NAME\", axis = 1)\n",
    "\n",
    "#For Gender we need to combine 0 (Female of child bearing potential) and 1 (Female of non-child bearing potential) into one category 0 (female), we convert 2 (Male) to 1 afterwards\n",
    "#Result of this processing: 0 = Female, 1 = Male\n",
    "\n",
    "SCDE.loc[SCDE[\"GENDER\"] == 1, \"GENDER\"] = 0 \n",
    "SCDE.loc[SCDE[\"GENDER\"] == 2, \"GENDER\"] = 1\n",
    "\n",
    "#SCOP is not a simple sum and needs additional preprocessing to get total score\n",
    "# In SCAU1-21, 9 is converted to 3. In SCAU22-25, 9 is converted to 0\n",
    "for i in range(1,26):\n",
    "    s = \"SCAU\" + str(i)\n",
    "    points = 0\n",
    "    if i < 22:\n",
    "        points = 3\n",
    "    SCOP.loc[SCOP[s] == 9, s] = points"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we perform our data merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First step of join: Merge non-longitudinal data\n",
    "data = pat_subset.merge(FMHS, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SOEC, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SCDE, how = \"inner\", on = \"PATNO\")\n",
    "data = data.merge(SIDT, how = \"inner\", on = \"PATNO\")\n",
    "\n",
    "\n",
    "#Second step of join: Merge in longitudinal data\n",
    "\n",
    "#This data table has duplicate entries for the same data, test is done before drug is administered and after\n",
    "data = data.merge(MSU3, how = \"inner\", on =\"PATNO\")\n",
    "\n",
    "data = data.merge(MSU1, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(MOCA, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(HPLT, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(BJLO, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(LNSQ, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(SEFL, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(GDSS, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(EPSS, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(SCOP, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(REMQ, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "data = data.merge(MSU2, how = \"inner\", on = [\"PATNO\", LED[long_flag]])\n",
    "\n",
    "duration = pd.read_csv(\"Medical_History/PD_Features.csv\").loc[:,[\"PATNO\", \"PDDXDT\"]]\n",
    "\n",
    "data = data.merge(duration, how = \"inner\", on = \"PATNO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Removing birthdate and project enrollment date and adding age as a function of these two columns\n",
    "\n",
    "#Fuction for month/year calculation of PD disease duration\n",
    "\n",
    "def pd_duration(row):\n",
    "    \n",
    "    enroll = float(row[\"ENROLLDT\"][0:2]) / 12 + float(row[\"ENROLLDT\"][-4:])\n",
    "    pdstart = float(row[\"PDDXDT\"][0:2]) / 12 + float(row[\"PDDXDT\"][-4:])\n",
    "    \n",
    "    return enroll - pdstart\n",
    "       \n",
    "data [\"AGE_BL\"] = data.apply(lambda row_wise: int(row_wise[\"ENROLLDT\"][-4:]) - int(row_wise[\"BIRTHDT\"]) , axis = 1)\n",
    "data[\"PD_DURATION_BL\"] = data.apply(pd_duration, axis = 1)\n",
    "\n",
    "data = data.drop([\"ENROLLDT\", \"BIRTHDT\", \"PDDXDT\"], axis = 1)\n",
    "\n",
    "#data.to_csv(output_filepath + '/joined_data.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we do some additional processing post merge and output the merged data table to a csv file so that it can be further processed in missingvalues.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In this cell we can do any final data inspection (Number of unique patients, shape, etc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape (670, 133)\n",
      "Number of unique PATNO: 247\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "#Inspecting the merged data\n",
    "\n",
    "#np.sort(data.columns.values)\n",
    "print( \"Data shape\", data.shape)\n",
    "print( \"Number of unique PATNO:\", data.PATNO.unique().size)\n",
    "\n",
    "data.loc[(data.AGE_BL > 30) & (data.PD_DURATION_BL <= 2) & (data.NHY < 3)  & (data.EVENT_ID == \"BL\") & (data.PD_MED_USE == 0), \"PATNO\"].unique().size \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
