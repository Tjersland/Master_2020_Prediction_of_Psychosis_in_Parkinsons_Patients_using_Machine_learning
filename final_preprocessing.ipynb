{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This cell is for defining various OPTIONS used for this notebook (working directory, how many rows and columns pandas displays for a dataframe, etc). \n",
    "\n",
    "#### Preferably this cell is also where we do important imports (for example pandas and numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "#Input the directory where your joined_data.csv is located \n",
    "os.chdir('C:/Users/Trond/Documents/Master 2020/Processed data')\n",
    "# os.chdir('C:/Users/Briggstone/Documents/Master 2020/Processed data')\n",
    "# os.chdir('C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data')\n",
    "\n",
    "#Where you want the csv file of the merged data to be placed\n",
    "#output_filepath = 'C:/Users/Briggstone/Documents/Master 2020/Processed data'\n",
    "output_filepath = 'C:/Users/MyPC/Documents/Andrijana/UiS/DATMAS Master oppgave/Processed data'\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Set ipython's max row display\n",
    "pd.set_option('display.max_row', 1000)\n",
    "\n",
    "# Set iPython's max column width to 50\n",
    "pd.set_option('display.max_columns', 50)\n",
    "\n",
    "\n",
    "# Joined imputed data to import, 0 = MODE/MEAN IMPUTATION, 1 = SIMILARITY MEASURE\n",
    "MV_FLAG = 1\n",
    "\n",
    "#The portion of data in the test set\n",
    "TEST_PORTION = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we import our joined imputed data based on MV_FLAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "if MV_FLAG == 0:\n",
    "    data = pd.read_csv('joined_data_mm.csv') # missing values filled with mean/median\n",
    "else: \n",
    "    data = pd.read_csv('joined_data_heom.csv') # missing values filled based on HEOM measure\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define the functions we need to calculate derived values from various variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for calculating derived values for various data tables\n",
    "\n",
    "def vlttot (df):\n",
    "    ''' Semantic Fluency\n",
    "    VLTANIM, VLTVEG,VLTFRUIT need to be summed in order to obtain a final score'''\n",
    "    \n",
    "    component_vars = [\"VLTANIM\", \"VLTVEG\", \"VLTFRUIT\"]\n",
    "    \n",
    "    df['VLTTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def remqtot (df):\n",
    "    '''REM sleep behavior disorder (RBD)'''\n",
    "    \n",
    "    component_vars = [\"STROKE\",\"HETRA\", \"PARKISM\", \"RLS\", \"NARCLPSY\", \"DEPRS\", \"EPILEPSY\", \"BRNINFM\", \"CNSOTH\"]\n",
    "        \n",
    "    score = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    \n",
    "    # 1 point if any of these component variables had a 1, else 0\n",
    "    score = pd.Series(np.where(score >= 1, 1, 0))\n",
    "    \n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    component_vars = [\"DRMVIVID\", \"DRMAGRAC\", \"DRMNOCTB\", \"SLPLMBMV\", \"SLPINJUR\", \\\n",
    "                      \"DRMVERBL\", \"DRMFIGHT\", \"DRMUMV\", \"DRMOBJFL\", \"MVAWAKEN\", \"DRMREMEM\", \"SLPDSTRB\"]\n",
    "    \n",
    "    score += df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "\n",
    "    df['REMTOT'] = score\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def gdsstot (df):\n",
    "    '''Geriatric Depression Scale'''\n",
    "    \n",
    "    component_vars = [\"GDSSATIS\", \"GDSDROPD\", \\\n",
    "    \"GDSEMPTY\", \"GDSBORED\", \"GDSGSPIR\", \"GDSAFRAD\", \"GDSHAPPY\", \"GDSHLPLS\", \"GDSHOME\", \"GDSMEMRY\", \"GDSALIVE\", \"GDSWRTLS\", \"GDSENRGY\", \\\n",
    "    \"GDSHOPLS\", \"GDSBETER\"]\n",
    "    \n",
    "    df['GDSSTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def sidttot (df):\n",
    "    '''Olfactory impairment: University of Pennsylvania Smell ID Test'''\n",
    "    component_vars = [\"UPSITBK1\", \"UPSITBK2\", \"UPSITBK3\", \"UPSITBK4\"]\n",
    "    \n",
    "    df['SIDTTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def epsstot (df):\n",
    "    '''Epworth Sleepiness Scale'''\n",
    "    \n",
    "    component_vars = [\"ESS1\", \"ESS2\", \\\n",
    "    \"ESS3\", \"ESS4\", \"ESS5\", \"ESS6\", \"ESS7\", \"ESS8\"]\n",
    "    \n",
    "    df['EPSSTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def scoptot(df):\n",
    "    '''Scales for Outcomes in Parkinson’s Disease–Autonomic'''\n",
    "\n",
    "    component_vars = [\"SCAU1\", \"SCAU2\", \\\n",
    "    \"SCAU3\", \"SCAU4\", \"SCAU5\", \"SCAU6\", \"SCAU7\", \"SCAU8\", \"SCAU9\", \"SCAU10\", \"SCAU11\", \"SCAU12\", \"SCAU13\", \\\n",
    "    \"SCAU14\", \"SCAU15\", \"SCAU16\", \"SCAU17\", \"SCAU18\", \"SCAU19\", \"SCAU20\", \"SCAU21\", \"SCAU22\", \"SCAU23\", \"SCAU24\", \"SCAU25\"]\n",
    "    \n",
    "    df['SCOPTOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "    \n",
    "\n",
    "def msu3tot(df):\n",
    "    '''Movement Disorders Society–Unified Parkinson Disease Rating Scale'''\n",
    "    \n",
    "    component_vars = ['NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR']\n",
    "       \n",
    "    df['MSU3TOT'] = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    #df.drop(component_vars, inplace = True, axis = 1) #cannot drop, variables needed in tremor and pigd\n",
    "\n",
    "    \n",
    "def tremor(df):\n",
    "    '''Tremor score'''\n",
    "    \n",
    "    component_vars = [\"NP2TRMR\", \"NP3PTRMR\", \"NP3PTRML\", \"NP3KTRMR\", \"NP3KTRML\", \"NP3RTARU\", \"NP3RTALU\", \"NP3RTARL\", \"NP3RTALL\", \\\n",
    "    \"NP3RTALJ\", \"NP3RTCON\"]\n",
    "    \n",
    "    df['TREMOR'] = df.loc[:, component_vars].mean(axis = 1, skipna = False)\n",
    "    #df.drop(component_vars, inplace = True, axis = 1) #cannot drop, variables needed in tremor and pigd\n",
    "    \n",
    "    \n",
    "def pigd(df):\n",
    "    '''PIGD score'''\n",
    "    \n",
    "    component_vars = [\"NP2WALK\", \"NP2FREZ\", \"NP3GAIT\", \"NP3FRZGT\", \"NP3PSTBL\"]\n",
    "    df['PIGD'] = df.loc[:, component_vars].mean(axis = 1, skipna = False)\n",
    "    \n",
    "    component_vars = ['NP3BRADY', 'NP3FACXP', 'NP3FRZGT', \\\n",
    "    'NP3FTAPL', 'NP3FTAPR', 'NP3GAIT', 'NP3HMOVL', 'NP3HMOVR', 'NP3KTRML', 'NP3KTRMR', 'NP3LGAGL', 'NP3POSTR', 'NP3PRSPL', 'NP3PRSPR', \\\n",
    "    'NP3PSTBL', 'NP3PTRML', 'NP3PTRMR', 'NP3RIGLL', 'PN3RIGRL', 'NP3RIGN', 'NP3RIGRU', 'NP3RISNG', 'NP3RTALJ', 'NP3RTALL', 'NP3RTALU', \\\n",
    "    'NP3RTARL', 'NP3RTARU', 'NP3RTCON', 'NP3SPCH', 'NP3TTAPL', 'NP3TTAPR', \"NP2TRMR\", \"NP2WALK\", \"NP2FREZ\" ]\n",
    "    #cannot drop before we discuss missing values\n",
    "    df.drop(component_vars, inplace = True, axis = 1) #drop everything from msu3tot, tremor and pig\n",
    "    \n",
    "\n",
    "def td_pigd_ratio(df):\n",
    "    '''Tremor/PIGD ratio'''\n",
    "    \n",
    "    component_vars = ['TREMOR', 'PIGD']\n",
    "    df['TD_PIGD_RATIO'] = df.apply(lambda x: ratio(x['TREMOR'], x['PIGD']), axis=1)\n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "\n",
    "    \n",
    "def ratio(x, y):\n",
    "    ''' Calculate TD/PGID ratio'''\n",
    "    \n",
    "    if y == 0:\n",
    "        if x == 0:\n",
    "            ratio = 0 #indeterminate\n",
    "        else: \n",
    "            ratio =1 #TD\n",
    "    elif x/y >= 1.15:\n",
    "        ratio = 1 #TD\n",
    "    elif x/y <= 0.9:\n",
    "        ratio = 2 #PIGD\n",
    "    else:\n",
    "        ratio = 0 #indeterminate \n",
    "    return ratio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we define functions for encoding and dichotomizing variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for encoding and dichotomizing variables\n",
    "\n",
    "def famhist(df):\n",
    "    '''Family history of Parkinson's Disease'''\n",
    "    \n",
    "    component_vars = [\"BIOMOMPD\", \"BIODADPD\", \"FULSIBPD\", \"HAFSIBPD\", \"MAGPARPD\", \"PAGPARPD\", \"MATAUPD\", \"PATAUPD\", \"KIDSPD\"]\n",
    "        \n",
    "    score = df.loc[:, component_vars].sum(axis = 1, skipna = False)\n",
    "    \n",
    "    # if score >= 1 then 1, else 0\n",
    "    # if score = NaN, then 0\n",
    "    score = pd.Series(np.where(score >= 1, 1, 0))\n",
    "    \n",
    "    df.drop(component_vars, inplace = True, axis = 1)\n",
    "    df['FAMHIST'] = score\n",
    "    \n",
    "    \n",
    "def sleepy(df):\n",
    "    '''Dichotomize EPSSTOT, Epworth Sleepiness Scale'''\n",
    "    \n",
    "    # if score < 10 subjects will be classified as 0 (not sleepy)\n",
    "    # if score >= 10 subject will be classified as 1 (sleepy).\n",
    "    df['SLEEPY'] = df['EPSSTOT'].apply(lambda x: np.where(x >=10, 1, 0))\n",
    "\n",
    "    df.drop('EPSSTOT', inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "def depr(df):\n",
    "    '''Dichotomize GDSSTOT, Geriatric Depression Scale'''\n",
    "    \n",
    "    # if score <5 subjects will be classified as 0 (non-depressed).\n",
    "    # if score >= 5 subjects will be classified as 1 (depressed) \n",
    "    df['DEPR'] = df['GDSSTOT'].apply(lambda x: np.where(x >=5, 1, 0))\n",
    "\n",
    "    df.drop('GDSSTOT', inplace = True, axis = 1)\n",
    "\n",
    "\n",
    "def rbd(df):\n",
    "    '''Dichotomize REMTOT, REM sleep behavior disorder (RBD)'''\n",
    "       \n",
    "    # if score <5 subjects will be classified as 0 (RBD negative).\n",
    "    # if score >= 5 subjects will be classified as 1 (RBD positive) \n",
    "    df['RBD'] = df['REMTOT'].apply(lambda x: np.where(x >=5, 1, 0))\n",
    "\n",
    "    df.drop('REMTOT', inplace = True, axis = 1)\n",
    "    \n",
    "\n",
    "def hall(df):\n",
    "    '''Dihotomize NP1HALL dependent variable'''\n",
    "    \n",
    "    # if the patient has not suffered hallucinations, we consider it 0\n",
    "    # if the patient has suffered >= 1 times hallucinations, we consider it 1   \n",
    "    df['HALL'] = df['NP1HALL'].apply(lambda x: np.where(x >=1, 1, 0))\n",
    "\n",
    "    df.drop('NP1HALL', inplace = True, axis = 1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### All preprocessing functions together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    '''All preprocessing together'''\n",
    "    vlttot(df)\n",
    "    remqtot(df)\n",
    "    gdsstot(df)\n",
    "    sidttot(df)\n",
    "    epsstot(df)\n",
    "    scoptot(df)\n",
    "    msu3tot(df)\n",
    "    tremor(df)\n",
    "    pigd(df)\n",
    "    td_pigd_ratio(df)\n",
    "    famhist(df)\n",
    "    sleepy(df)\n",
    "    depr(df)\n",
    "    rbd(df)\n",
    "    hall(df)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we apply our preprocessing functions on the data and check out the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PATNO</th>\n",
       "      <th>EDUCYRS</th>\n",
       "      <th>GENDER</th>\n",
       "      <th>EVENT_ID</th>\n",
       "      <th>PD_MED_USE</th>\n",
       "      <th>NP1COG</th>\n",
       "      <th>MCATOT</th>\n",
       "      <th>DVT_DELAYED_RECALL</th>\n",
       "      <th>JLO_TOTRAW</th>\n",
       "      <th>LNS_TOTRAW</th>\n",
       "      <th>AGE_BL</th>\n",
       "      <th>VLTTOT</th>\n",
       "      <th>SIDTTOT</th>\n",
       "      <th>SCOPTOT</th>\n",
       "      <th>MSU3TOT</th>\n",
       "      <th>TD_PIGD_RATIO</th>\n",
       "      <th>FAMHIST</th>\n",
       "      <th>SLEEPY</th>\n",
       "      <th>DEPR</th>\n",
       "      <th>RBD</th>\n",
       "      <th>HALL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3400</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>BL</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39</td>\n",
       "      <td>63.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3400</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V04</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3400</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V06</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>39</td>\n",
       "      <td>53.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3400</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V12</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>39</td>\n",
       "      <td>49.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3400</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>V08</td>\n",
       "      <td>6</td>\n",
       "      <td>2.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>39</td>\n",
       "      <td>59.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PATNO  EDUCYRS  GENDER EVENT_ID  PD_MED_USE  NP1COG  MCATOT  \\\n",
       "0   3400     18.0     0.0       BL           0     0.0    24.0   \n",
       "1   3400     18.0     0.0      V04           3     1.0    29.0   \n",
       "2   3400     18.0     0.0      V06           2     1.0    30.0   \n",
       "3   3400     18.0     0.0      V12           4     1.0    29.0   \n",
       "4   3400     18.0     0.0      V08           6     2.0    30.0   \n",
       "\n",
       "   DVT_DELAYED_RECALL  JLO_TOTRAW  LNS_TOTRAW  AGE_BL  VLTTOT  SIDTTOT  \\\n",
       "0                54.0        13.0        10.0      39    63.0     30.0   \n",
       "1                54.0        12.0        12.0      39    49.0     30.0   \n",
       "2                44.0        12.0        10.0      39    53.0     30.0   \n",
       "3                54.0        12.0         2.0      39    49.0     30.0   \n",
       "4                54.0        12.0        12.0      39    59.0     30.0   \n",
       "\n",
       "   SCOPTOT  MSU3TOT  TD_PIGD_RATIO  FAMHIST  SLEEPY  DEPR  RBD  HALL  \n",
       "0     12.0     17.0              2        0       1     1    1     0  \n",
       "1     20.0     40.0              2        0       0     1    1     0  \n",
       "2     22.0     28.0              0        0       0     1    0     0  \n",
       "3     17.0     16.0              2        0       1     1    0     0  \n",
       "4     25.0     32.0              2        0       1     1    1     0  "
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess(data)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### In this cell we seperate out data set into training and test sets and apply standardization to numeric columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = data.pop(\"HALL\")\n",
    "X = data\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split( X, Y, test_size= TEST_PORTION, random_state= 1, stratify= Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Trond\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:543: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self.obj[item] = s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15.613080684596577"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def standardize_df (df, standardization):\n",
    "    \n",
    "    columns = standardization.loc[:, \"COLUMN_NAME\"].values\n",
    "    for i,c in enumerate(columns):\n",
    "        df.loc[:,c] -= standardization.at[i,\"MEAN\"]\n",
    "        df.loc[:,c] /= standardization.at[i,\"STD\"]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "column_types = pd.read_csv(\"Column_Data_Types_Final.csv\")\n",
    "\n",
    "numeric_columns = column_types.loc[column_types.DATA_TYPE == \"Numeric\", \"COLUMN_NAME\"].values\n",
    "\n",
    "mean = np.mean(X_train.loc[:, numeric_columns])\n",
    "std = np.std(X_train.loc[:, numeric_columns])\n",
    "\n",
    "standardization = pd.DataFrame(numeric_columns, columns = [\"COLUMN_NAME\"])\n",
    "standardization[\"MEAN\"] = mean.values\n",
    "standardization[\"STD\"] = std.values\n",
    "\n",
    "standardize_df(X_train, standardization)\n",
    "np.std(X_train.loc[:, numeric_columns])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
